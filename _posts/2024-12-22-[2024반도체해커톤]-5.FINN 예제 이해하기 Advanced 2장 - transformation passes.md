---
title: "[2024반도체해커톤] 5.FINN 예제 이해하기 Advanced 2장 - Transformation passes"
date: 2024-12-22 15:20:00 +09:00
categories: [Project, 2024_2 반도체해커톤,]
tags:
  [
    verilog,
    systemverilog,
    Vivado,
    Vitis,
    Xilinx,
    FINN,
    Bretivas
  ]
---

## 환경사항
사용하고 있는 환경은 다음과 같다.

| 이름                      | 버전       | 기타 정보 |
| :-------------------------------| :-----------------| :-------: |
| Vivado			| 2023.2		| O	|
| Vitis			| 2023.2		| O	|
| WSL2			| 5.15.167.4	| O	|
| Ubuntu			| 20.04.06	| O	|
| Docker Desktop		|		| O	|


## 목차 
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-0.WLS2-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%ED%95%98%EB%93%9C%EC%9B%A8%EC%96%B4-%EC%9E%A5%EB%B9%84-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0/">0. WSL2 환경에서 하드웨어 장비 연결하기<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-1.%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0/">1. 환경 설정하기<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-2.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-1%ED%8E%B8-How-to-work-with-onnx/">2. FINN 예제 이해하기 1편 Basics - How to used finn<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-3.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-2%ED%8E%B8-Brevitas-netowrk-import-via-QONNX/">3. FINN 예제 이해하기 2편 - Brevitas network import via QONNX<br>
4. FINN 예제 이해하기 3편 - custom_analysis_pass<br>
5. FINN 예제 이해하기 4편 - custom_op<br>

## 이번 챕터에서는 무엇을 했나요?
저번 챕터와 마찬가지로 며칠동안은 FINN에서 제공하는 예제를 이해하는 시간을 가졌습니다.

이번 챕터는 FINN의 변환 패스에 대한 개념을 설명하고 예제를 통해 변환의 절차를 공부할 예정입니다.

### General Information

* 주어진 그래프를 변경(변형)합니다.
* 입력을 변경합니다: ModelWrapper
* 변경된 모델(ModelWrapper)과 플래그 `model_was_changed`를 반환합니다.

<br>

`Transformation passes` 는 `base class`가 있으며 이 클래스를 상속해야 합니다. 

변환은 ModelWrapper의 `.transform` 함수를 사용하여 적용해야 합니다. 

이 함수는 기본적으로 입력 모델의 `deep copy`를 만듭니다. 

다음 셀은 ModelWrapper의 `.transform`을 보여줍니다.

---
## 5.1 transform() from ModelWrapper
---
```python
from qonnx.core.modelwrapper import ModelWrapper
showSrc(ModelWrapper.transform)
```
```bash
#출력
def transform(self, transformation, make_deepcopy=True, cleanup=True):
    """Applies given Transformation repeatedly until no more changes can be made
    and returns a transformed ModelWrapper instance.

    - make_deepcopy : operates on a new (deep)copy of model.
    - cleanup : execute cleanup transformations before returning
    """
    transformed_model = self
    if make_deepcopy:
        transformed_model = copy.deepcopy(self)
    if self.fix_float64:
        (transformed_model, model_was_changed) = DoubleToSingleFloat().apply(transformed_model)
    model_was_changed = True
    while model_was_changed:
        (transformed_model, model_was_changed) = transformation.apply(transformed_model)
    if cleanup:
        transformed_model.cleanup()
    return transformed_model
```
<br>

함수가 호출되면 모델, 트랜스폼 이름, 필요한 경우 make_deepcopy 플래그가 전달됩니다. 모델의 복사본을 만들지 않을 수도 있습니다. 이 경우 `make_deepcopy` 를 False로 설정해야 합니다. 

그러면 `if make_deepcopy:` 분기가 취해지지 않고 모델의 복사본이 만들어지지 않습니다.

또한 모델의 `fix_float64` 속성이 확인되고 `True` 로 설정된 경우 모든 이중값이 부동 소수점으로 변환됩니다. 이렇게 하면 모델의 올바른 기능을 보장합니다.

변경되지 않은 모델은 나중에 이 변수를 변환에 전달하기 위해 `transformed_model` 변수로 전달됩니다.

`model_was_changed`는 변환을 두 번 이상 적용해야 하는지 여부를 나타냅니다. 
적어도 한 번은 적용해야 하므로 `model_was_changed`를 먼저 True로 설정한 다음 변환 함수의 반환 값에 따라 변환을 두 번 이상 적용할 수 있습니다.

- **중요**: 이 함수의 구조상 `model_was_changed`는 어느 시점에서 반드시 False로 설정되어야 합니다. 그렇지 않으면 루프가 무한 반복됩니다.

각각의 새로운 변환은 기본 클래스의 스키마와 일치해야 하며, 변경된 모델과 `model_was_changed`에 대한 부울 값을 반환하는 `apply(model)` 함수를 최소한 포함해야 합니다.

#### 5.1 이해하기 
위 코드는 `ModelWrapper` 클래스의 `transform` 매서드를 보여주게 됩니다. 

이 메서드는 특정 변환(Transformation)을 적용하여 최종적으로 변환된 모델을 반환하는 역할을 합니다. 

이해한 바로는 다음과 같습니다.

1. **`Deep Copy`** 를 여부에 따라 변환 작업을 수행할 모델을 초기화 한 뒤 

2. 필요한 경우, 모델에서 `float64`를 `float23`로 변환을 합니다.

3. 지정된 변환 작업(`transformation`)을 반복적으로 적용하여 모델을 최적화하거나 변환을 합니다.

4. 선택적으로 정리(`cleanup`) 작업을 수행하여 최적 모델을 반환합니다.
<br>

---
## 5.2 Transformation Base Class
---
```python
from qonnx.transformation.base import Transformation

showSrc(Transformation)
```
```bash
#출력
class Transformation(ABC):
    """Transformation class all transformations are based on. Contains only
    abstract method apply() every transformation has to fill."""

    def __init__(self):
        super().__init__()

    @abstractmethod
    def apply(self, model):
        pass
```

기본 클래스는 모델을 입력으로 가져오는 하나의 추상 메서드(`apply()`)만 있는 추상 클래스(`import ABC`)입니다. 
변환이 어떤 모습이어야 하는지 보여주기 위해 다음 예제는 FINN에서 가져온 것입니다.

#### 5.2. 이해하기

이 코드는 `Transformation` 클래스와 해당 코드를 정의하는 방식에 대해 설명을 합니다. 

이 코드의 형식을 맞춰 코드를 작성하여 `일관성`을 유지하고, 다양한 작업에 재사용할 수 있는 `유연성`을 얻을 수 있습니다.
<br>

---
## 5.3 Example - ConvertSubToAdd
---

변환은 모델의 모든 뺄셈 노드를 적절한 부호를 가진 덧셈 노드로 바꿉니다. 

이를 위해 뺄셈 노드가 하나 포함된 onnx 모델이 로드됩니다. 
    
Netron을 사용하여 변환 전과 후의 결과를 시각화합니다.

```python
import os
notebook_dir = os.environ['FINN_ROOT'] + "/notebooks"

import onnx
onnx_model = onnx.load(notebook_dir + "/LFCW1A1.onnx")
from qonnx.core.modelwrapper import ModelWrapper
onnx_model = ModelWrapper(onnx_model)
```
<br>
```python
showInNetron(notebook_dir + "/LFCW1A1.onnx")
```

![1.1](./1.1.PNG)

#### 5.3. 이해하기

1. **`import os:`**:
    - 표준 라이브러리 `os`를 가져옵니다. 이 함수는 운영체제와 관련된 기능을 제공하며, 특히 환경 변수와 파일 경로를 다룰 때 유용합니다.
2. **`notebook_dir = os.environ['FINN_ROOT'] + "/notebooks":`**:
    - FINN 환경 변수에서 FINN_ROOT 경로를 가져와, 그 하위 디렉터리 notebooks 경로를 만듭니다.
3. **`import onnx:`**:
    - ONNX 라이브러리를 가져옵니다.
    - ONNX 모델 파일을 로드하거나 저장하는 작업에 사용됩니다. 머신 러닝 모델의 구조와 가중치를 다루는 데 유용합니다.
4. **`onnx_model = onnx.load(notebook_dir + "/LFCW1A1.onnx"):`**:
    - 지정된 경로에서 ONNX 형식의 모델 파일을 로드합니다.
    - notebook_dir + "/LFCW1A1.onnx": FINN 노트북 디렉터리에서 LFCW1A1.onnx 모델 파일 경로를 생성합니다.
    - onnx.load(...): 해당 경로에 있는 ONNX 모델 파일을 읽어 Python 객체로 반환합니다.
5. **`from qonnx.core.modelwrapper import ModelWrapper:`**:
    - QONNX 라이브러리의 core.modelwrapper 모듈에서 ModelWrapper 클래스를 가져옵니다.
    - ONNX 모델을 다루기 쉽게 만들어주는 클래스입니다.
    - 예를 들어, 모델의 그래프 구조, 입력, 출력, 노드 등을 쉽게 수정하거나 분석할 수 있습니다.
6. **`onnx_model = ModelWrapper(onnx_model):`**:
    - onnx.load()로 로드한 ONNX 모델 객체를 ModelWrapper로 감쌉니다.
    - 기존 ONNX 모델 객체를 확장하여 더 많은 기능(예: 노드 검색, 입력/출력 정의 수정 등)을 제공합니다.
    - ModelWrapper는 FINN 프로젝트에서 ONNX 모델을 최적화하거나 조작할 때 사용됩니다
<br>

---
## 5.4 Transformation - sub 를 add로 변환 
---
```python
from qonnx.transformation.base import Transformation

class ConvertSubToAdd(Transformation):
    def apply(self, model):
        graph = model.graph
        for n in graph.node:
            if n.op_type == "Sub":
                A = model.get_initializer(n.input[1])
                if A is not None:
                    n.op_type = "Add"
                    model.set_initializer(n.input[1], -A)
        return (model, False)
```
<br>

먼저 변환 클래스를 가져와야 합니다. 그런 다음 기본 클래스에서 파생된 새 변환을 위한 클래스를 만들 수 있습니다. 이 경우 변환에는 `apply()`함수만 있습니다.

모든 노드는 먼저 모델에서 그래프를 추출한 다음 노드 목록을 반복하여 확인합니다.

 .op_type을 사용하여 노드의 연산 유형을 확인할 수 있으며, 노드가 뺄셈 노드인 경우 `if n.op_type == “Sub”` 조건이 참이면 노드의 연산 유형이 확인됩니다. 
 
 노드의 뺄셈 입력에 값이 없을 수도 있으며, 이는 `model.get_initializer(n.input[1])` 로 확인할 수 있습니다.

- **중요:** FINN은 항상 특정 입력 순서를 가정하며, 이는 사용자 정의 연산 노드를 추가로 생성하려는 경우 특히 중요합니다.

입력이 초기화되면 노드의 연산 유형이 `“Add”`로 변환되며, 이는 등호를 사용하여 간단히 수행할 수 있습니다. 

그런 다음 초기 값의 부호를 변경해야 합니다. 이를 위해 ModelWrapper 함수 `.set_initializer` 를 사용할 수 있습니다.

마지막에는 변환이 한 번만 실행되어야 하므로 변경된 모델이 반환되고 `model_was_changed` 가 False로 설정됩니다.
<br>

#### 5.4. 이해하기

1. **`from qonnx.transformation.base import Transformation:`**:
    - QONNX 라이브러리의 transformation.base 모듈에서 Transformation 클래스를 가져옵니다.
    - QONNX의 Transformation은 ONNX 모델의 그래프를 수정하거나 최적화하는 데 사용되는 변환 작업의 기본 클래스입니다.
    - 사용자 정의 변환 클래스는 이 클래스를 상속받아 특정 변환 로직을 구현합니다.
2. **`class ConvertSubToAdd(Transformation):`**:
    - Transformation을 상속받는 사용자 정의 클래스 ConvertSubToAdd를 정의합니다.
    - 이 클래스는 그래프의 Sub 연산을 Add 연산으로 변환하는 작업을 수행합니다.
3. **`def apply(self, model):`**:
    - 변환 작업을 수행하는 메서드로, 변환의 핵심 로직이 구현됩니다.
    - model: 변환을 적용할 대상 ONNX 모델 (ModelWrapper 객체로 전달됨).
    - 반환값:
        - model: 변환이 적용된 모델.
        - False: 이 변환으로 인해 추가적인 변환이 필요하지 않음을 나타냄.
4. **`graph = model.graph:`**:
    - 모델의 그래프 객체를 가져옵니다.
    - ONNX 모델의 graph는 네트워크의 전체 구조를 나타냅니다.
    - 그래프는 노드, 초기값(initializers), 입력(input), 출력(output) 등으로 구성됩니다.
5. **`for n in graph.node:`**:
    - 그래프의 각 노드에 대해 반복 작업을 수행합니다.
    - graph.node는 그래프에 포함된 모든 연산(노드) 리스트를 제공합니다.
    - 각 n은 ONNX 모델 내의 하나의 연산 노드를 나타냅니다.
6. **`if n.op_type == "Sub":`**:
    - 현재 노드의 연산 유형(op_type)이 "Sub"(뺄셈)인지 확인합니다.
    - "Sub" 연산 노드를 변환 대상으로 지정합니다.
7. **`A = model.get_initializer(n.input[1]):`**:
    - 뺄셈 연산에서 두 번째 입력값(input[1])의 초기값(initializer)을 가져옵니다.
    - model.get_initializer(...): 모델에서 초기값(상수 값)을 검색합니다.
    - n.input[1]: 현재 노드의 두 번째 입력 이름.
8. **`if A is not None:`**:
    - 두 번째 입력값이 초기값으로 존재하는지 확인합니다.
    - 초기값이 없는 경우, 변환 작업을 생략합니다.
    - 초기값이 있으면 변환 작업을 계속 진행합니다.
9. **`n.op_type = "Add"`**:
    - 노드의 연산 유형을 "Add"(덧셈)으로 변경합니다.
    - "Sub" 연산이 "Add" 연산으로 변환됩니다.
10. **`model.set_initializer(n.input[1], -A)`**:
    - 설명: 두 번째 입력값의 초기값을 음수로 변경합니다.
    - model.set_initializer(...): 특정 입력값의 초기값을 설정합니다.
    - -A: 기존 초기값 A를 음수로 바꿉니다.
    - "Sub" 연산이 "Add"로 바뀌고, b - a는 b + (-a)로 표현됩니다.
11. **`return (model, False)`**:
    - 변환된 모델과 추가 변환 여부를 반환합니다.
    - model: 변환된 ONNX 모델 객체.
    - False: 추가적인 변환을 적용하지 않아도 됨을 나타냅니다.


**즉 동일한 연산을 다른 형태로 표현하여 호환성, 최적화 또는 단순화를 목적으로 사용되는 것 같습니다.**

```python
onnx_model_transformed = onnx_model.transform(ConvertSubToAdd())
onnx_model_transformed.save('/tmp/LFCW1A1_changed.onnx')
```
<br>

```python
showInNetron('/tmp/LFCW1A1_changed.onnx')
```
![1.2](./1.2.PNG)
<br>

---
## 5.5. Parallel Transformation - 1
---
FINN의 일부 변환은 개별 노드에서 병렬로 수행될 수 있습니다. 

이를 위해서는 다음 `NodeLocalTransformation`이 필요합니다:

```python
from qonnx.transformation.base import NodeLocalTransformation

showSrc(NodeLocalTransformation)
```
```bash
#출력
class NodeLocalTransformation(Transformation):
    """
    Parent class for transformations, which can be executed locally to one node
    by accessing and modifying the attributes of only that node.
    This class can then automatically parallelize the transformation.
    Transformations sublcassing NodeLocalTransformation must implement the
    abstract method applyNodeLocal(). A read-only copy of the model is available
    as a member variable ref_input_model, but any modifications there will be
    disregarded.

    To control the degree of parallelization, specify the num_workers argument
    in the constructor, using one of the following values:
    * None: use NUM_DEFAULT_WORKERS environment variable
    * 0: use all available CPU cores
    * (any other int>0): set number of parallel workers
    """
    
    def __init__(self, num_workers=None):
        """
        클래스 초기화 메서드입니다. 병렬 처리에 사용할 작업자 수를 설정합니다.

        Parameters:
        num_workers (int or None): 병렬 처리할 작업자 수. None이면 기본값을 사용하고, 0이면 모든 CPU 코어를 사용합니다.
        """
        super().__init__()
        if num_workers is None:
            self._num_workers = get_num_default_workers()  # 환경 변수에서 기본 작업자 수를 가져옵니다.
        else:
            self._num_workers = num_workers  # 명시된 작업자 수를 사용합니다.
        
        assert self._num_workers >= 0, "Number of workers must be nonnegative."
        
        # num_workers가 0이면 가능한 모든 CPU 코어를 사용합니다.
        if self._num_workers == 0:
            self._num_workers = mp.cpu_count()

    @abstractmethod
    def applyNodeLocal(self, node):
        """
        이 메서드는 각 노드에 대해 변환을 적용하는 추상 메서드입니다.
        이 메서드를 구현하려면 해당 변환 작업을 서브클래스에서 작성해야 합니다.

        Parameters:
        node: 변환을 적용할 단일 노드입니다.

        Returns:
        node (Node): 변환이 적용된 노드
        run_again (bool): 변환을 다시 적용해야 하는지 여부
        """
        pass
    
    def apply(self, model):
        """
        모델에 대해 병렬 변환을 수행하는 메서드입니다. 각 노드에 대해 applyNodeLocal을 병렬로 실행합니다.

        Parameters:
        model (ModelWrapper): 변환을 적용할 ONNX 모델입니다.

        Returns:
        tuple: 변환된 모델과, 추가적인 변환이 필요한지 여부를 나타내는 플래그입니다.
        """
        # 모델을 깊은 복사하여 ref_input_model에 저장합니다. 이후 노드는 이 모델을 참조하여 읽기 전용으로 처리됩니다.
        self.ref_input_model = copy.deepcopy(model)
        
        # 현재 모델에서 모든 노드를 제거합니다.
        old_nodes = []
        for i in range(len(model.graph.node)):
            old_nodes.append(model.graph.node.pop())

        # multiprocessing을 사용하여 노드 변환을 병렬로 수행합니다.
        with mp.Pool(self._num_workers) as p:
            # 노드 각각에 대해 applyNodeLocal을 병렬로 실행합니다.
            new_nodes_and_bool = p.map(self.applyNodeLocal, old_nodes, chunksize=1)

        # 변환 후 노드를 다시 모델에 추가하고, 변환이 다시 실행되어야 하는지 확인합니다.
        run_again = False
        for node, run in reversed(new_nodes_and_bool):
            # 변환된 노드를 모델에 다시 붙입니다.
            model.graph.node.append(node)
            if run is True:  # 변환 후, 다시 변환이 필요한 경우 플래그를 True로 설정
                run_again = True

        # 모델과 추가 변환이 필요한지 여부를 반환합니다.
        return (model, run_again)

```
<br>

병렬로 실행할 변환에는 `applyNodeLocal()` 메서드가 구현되어 있어야 합니다.

변환은 단일 노드에서만 실행되며 병렬 변환은 전체 모델이나 텐서에 액세스할 수 없다는 점에 유의하세요. 
 
병렬화는 특히 컴파일과 같이 시간이 많이 걸리는 변환을 보다 효과적으로 실행할 수 있다는 장점이 있습니다. 

병렬화 정도를 제어하기 위해 `num_workers` 인수를 지정할 수 있습니다.

Docker 컨테이너가 시작되면 환경 변수 `NUM_DEFAULT_WORKERS`는 기본적으로 4로 설정되며, 시스템에 따라 이 값을 늘리거나 줄일 수 있습니다. 

병렬화를 허용하는 변환을 호출할 때 작업자 수를 수동으로 특정 값으로 설정할 수도 있습니다. 값을 0으로 설정하면 사용 가능한 모든 CPU 코어가 사용됩니다.


#### 5.5. 이해하기
`NodeLocalTransforatation` 클래스는 ONNX 모델의 변환을 병렬로 수행할 수 있게 해주는 기본 클래스입니다.

특정 노드에 대해서만 변환을 적용하며, 이 클래스는 각 노드를 독립적으로 변환하고 이를 병렬화하여 효율적인 처리 속도를 제공합니다.

1. **`def __init__(self, num_workers=None):`**
    - **num_workers`**는 병렬 작업에 사용할 CPU 코어 수를 설정합니다. 기본값은 None이며, 이 경우 환경 변수 NUM_DEFAULT_WORKERS를 사용합니다.
        - num_workers == 0이면 사용 가능한 모든 CPU 코어를 사용하여 병렬화를 수행합니다.

        - **self._num_workers**는 실제로 사용되는 작업자 수를 설정합니다.

2. **`applyNodeLocal(self, node):`**
    - 이 메서드는 `NodeLocalTransformation`을 상속하는 클래스에서 구현해야 하는 `추상 메서드`입니다.

    - node: 변환을 적용할 단일 노드입니다. 서브클래스에서 각 노드에 대해 수행할 구체적인 변환 작업을 정의해야 합니다.

    - 구현 필요: 이 메서드는 서브클래스에서 구현되어야 하며, 변환 후 노드를 반환하고, 변환을 계속해야 할지 여부를 `run_again` 값으로 반환해야 합니다

3. **`apply(self, model):`**
    - 모델을 깊은 복사하여 ref_input_model로 저장합니다. 이는 원본 모델을 수정하지 않도록 하기 위함입니다.

    - 모델의 모든 노드를 old_nodes 리스트에 저장하고, 모든 노드를 제거합니다.

    - **mp.Pool**을 사용하여 각 노드에 대해 병렬로 applyNodeLocal 메서드를 실행합니다.

    - 변환 후, 노드를 모델에 다시 추가하고, 만약 변환이 다시 필요하다면 run_again 플래그를 **True**로 설정합니다.
    
    - run_again 값에 따라 추가 변환이 필요한지 여부를 확인하고 이를 반환합니다.


- 전체적인 흐름은 다음과 같습니다.
    1. 초기화: __init__() 생성자에서 num_workers를 설정하여 병렬 처리할 작업자 수를 결정합니다.

    2. 노드 변환: applyNodeLocal() 메서드를 서브클래스에서 구현하여, 각 노드에 대해 수행할 변환 작업을 정의합니다.

    3. 병렬화: apply() 메서드는 mp.Pool을 사용하여 모든 노드에 대해 변환 작업을 병렬로 수행합니다.

    4. 변환 후 처리: 변환된 노드는 모델에 다시 추가되고, 모델이 변환되어 다시 적용해야 할 경우 **run_again**을 반환하여 추가 변환을 할지 결정합니다.

- 이 클래스는 병렬 처리를 통해 효율적인 모델 변환을 지원하며, 각 노드에 독립적인 변환을 적용하여 모델 변환 속도를 크게 향상시킵니다.
<br>

---
## 5.6. Parallel Transformation - 2
---

다음에서는 cpp 시뮬레이션에 사용되는 컴파일 변환을 예로 들어 구현을 자세히 살펴보고자 합니다.

```python
from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim

showSrc(CompileCppSim)
```
```bash
#출력
class CompileCppSim(NodeLocalTransformation):
    """For every node: compile C++ code in node attribute "code_gen_dir_cppsim"
    and save path to executables in node attribute "executable_path".
    All nodes in the graph must have the fpgadataflow backend attribute.

    To use these executables, exec_mode must be set to "cppsim" (using transformation
    SetExecMode) and the model has to be executed using execute_onnx() from
    finn.core.onnx_exec

    * num_workers (int or None) number of parallel workers, see documentation in
      NodeLocalTransformation for more details.
    """

    def __init__(self, num_workers=None):
        super().__init__(num_workers=num_workers)

    def applyNodeLocal(self, node):
        op_type = node.op_type
        if is_hls_node(node):
            try:
                # lookup op_type in registry of CustomOps
                inst = registry.getCustomOp(node)
                # ensure that code is generated
                assert (
                    inst.get_nodeattr("code_gen_dir_cppsim") != ""
                ), """Node
                attribute "code_gen_dir_cppsim" is not set. Please run
                Transformation PrepareCppSim first."""
                # call the compilation function for this node
                inst.compile_singlenode_code()
                # ensure that executable path is now set
                assert (
                    inst.get_nodeattr("executable_path") != ""
                ), """Transformation
                compile was not successful, there is no path to executables set
                in node attribute "executable_path"."""
            except KeyError:
                # exception if op_type is not supported
                raise Exception("Custom op_type %s is currently not supported." % op_type)
        return (node, False)
```
<br>

이 클래스는 NodeLocalTransformation 클래스에서 파생되며 hls 노드인 모든 노드에서 컴파일을 수행합니다.

#### 5.6. 이해하기 



---