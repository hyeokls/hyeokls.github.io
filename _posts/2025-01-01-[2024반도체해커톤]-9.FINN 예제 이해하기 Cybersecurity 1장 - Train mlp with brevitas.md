---
title: "[2024반도체해커톤] 9. FINN 예제 이해하기 Cybersecurity 1장 - Train mlp with brevitas"
date: 2025-01-01 13:50:00 +09:00
categories: [Project, 2024_2 반도체해커톤,]
tags:
  [
    verilog,
    systemverilog,
    Vivado,
    Vitis,
    Xilinx,
    FINN,
    Bretivas
  ]
---

## 환경사항
사용하고 있는 환경은 다음과 같다.

| 이름                      | 버전       | 기타 정보 |
| :-------------------------------| :-----------------| :-------: |
| Vivado			| 2023.2		| O	|
| Vitis			| 2023.2		| O	|
| WSL2			| 5.15.167.4	| O	|
| Ubuntu			| 20.04.06	| O	|
| Docker Desktop		|		| O	|


## 목차 
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-0.WLS2-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%ED%95%98%EB%93%9C%EC%9B%A8%EC%96%B4-%EC%9E%A5%EB%B9%84-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0/">0. WSL2 환경에서 하드웨어 장비 연결하기<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-1.%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0/">1. 환경 설정하기<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-2.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-1%ED%8E%B8-How-to-work-with-onnx/">2. FINN 예제 이해하기 1편 Basics - How to used finn<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-3.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-2%ED%8E%B8-Brevitas-netowrk-import-via-QONNX/">3. FINN 예제 이해하기 2편 - Brevitas network import via QONNX<br>

# 이번 챕터에서는 무엇을 했나요?
이번은 `cybersecurity`챕터에서의 과정을 공부를 진행하였습니다.

---
## 9.0.1. Train a Quantized MLP on UNSW-NB15 with Brevitas
---
**브레비타스로 UNSW-NB15에서 정량화된 MLP 훈련하기**

이 노트북에서는 [Brevitas](https://github.com/Xilinx/brevitas)를 사용하여 양자화된 가중치와 활성화가 있는 양자화된 다층 퍼셉트론(MLP)을 생성, 훈련 및 내보내는 방법을 설명합니다.

특히, 당면한 작업은 UNSW-NB15 데이터 세트의 정량화된 변형을 학습하여 네트워크 패킷을 정상 또는 의심스러운(예: 공격자, 바이러스, 멀웨어 등에서 비롯된) 것으로 라벨링하는 것입니다. 

**신경망을 훈련하는 데 GPU가 필요하지 않습니다.** 이 MLP는 최신 x86 CPU에서 훈련할 수 있을 정도로 작으므로 이 튜토리얼을 따르는 데 GPU가 필요하지 않습니다. 

또는 훈련을 완전히 생략하려는 경우 MLP에 대해 미리 훈련된 매개변수를 제공합니다.


---
## 9.0.2. A quick introduction to the task and the dataset
---
## 과제 및 데이터 세트에 대한 간략한 소개

The task:[*네트워크 침입 탐지*](https://ieeexplore.ieee.org/abstract/document/283931)의 목표는 시스템 내부자와 외부 침입자 모두에 의한 컴퓨터 시스템의 무단 사용, 오용 및 남용을 실시간으로 식별하는 것입니다. 

이는 여러 가지 기법을 혼합하여 달성할 수 있으며, 머신러닝(ML) 기반 기법의 인기가 높아지고 있습니다. 

*데이터 세트: * 침입 탐지를 위한 ML 기반 방법에 사용할 수 있는 데이터 세트는 여러 가지가 있습니다.

호주 사이버 보안 센터(ACCS)에서 최신 네트워크 트래픽 시나리오를 반영할 수 있는 포괄적인 네트워크 기반 데이터 세트를 제공하기 위해 만든 **UNSW-NB15**는 이러한 데이터 세트 중 하나입니다. 

데이터 세트에 대한 자세한 내용은 [홈페이지](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/)에서 확인할 수 있습니다.

*성능 고려 사항: * FPGA는 일반적으로 어느 정도의 프로그래밍 기능을 제공하는 고성능 패킷 처리 시스템을 구현하는 데 사용됩니다.

네트워크에 병목 현상을 일으키지 않으려면 DNN 구현은 초당 수백만 개의 패킷이 될 수 있는 회선 속도로 악성 패킷을 탐지할 수 있어야 하며, 차세대 네트워킹 솔루션이 더 많은 처리량을 제공함에 따라
처리량. 

이 특정 사용 사례에서 FPGA 가속화를 고려해야 하는 좋은 이유입니다.

---
## 9.0.3. Outline 
---
* [Load the UNSW_NB15 Dataset](#load_dataset) 
* [Define a PyTorch Device](#define_pytorch_device)
* [Define the Quantized MLP Model](#define_quantized_mlp)
* [Define Train and Test  Methods](#train_test)
    * [(Option 1) Train the Model from Scratch](#train_scratch)
    * [(Option 2) Load Pre-Trained Parameters](#load_pretrained)
* [Network Surgery Before Export](#network_surgery)
* [Export to QONNX and Conversion to FINN-ONNX](#export_qonnx)

```python
import os
import onnx
import torch

model_dir = os.environ['FINN_ROOT'] + "/notebooks/end2end_example/cybersecurity"
```
<br>

---
## 9.1. Load the UNSW_NB15 Dataset
---
**Datasete Quantization **

이 노트북의 목표는 나중에 FINN 컴파일러에서 생성된 FPGA 가속기로 배포할 양자화된 신경망(QNN)을 훈련하는 것입니다.

입력에 대해 다양한 정밀도를 선택할 수 있지만, [Murovic and Trost](https://ev.fe.uni-lj.si/1-2-2019/Murovic.pdf)는 이전에 입력을 실제로 이진화하면서도 여전히 좋은(90% 이상) 정확도를 얻을 수 있음을 보여주었습니다.

여기서 간단히 반복하는 Murovic과 Trost가 정의한 절차에 따라 데이터 집합의 이진 표현을 만들 것입니다:

* 원래 기능은 정수, 부동 숫자, 문자열에 이르기까지 다양한 형식을 가지고 있습니다.

* 예를 들어 패킷 수명을 나타내는 정수는 최대값을 포함할 수 있는 만큼의 비트로 이진화됩니다. 

* 또 다른 경우는 문자열(프로토콜)로 형식이 지정된 기능으로, 각 기능에 대해 서로 다른 문자열의 수를 모두 세고 적절한 비트 수로 코딩하여 2진수로 변환하는 경우입니다.

* 부동 소수점 숫자는 고정 소수점 표현으로 다시 포맷됩니다.

* 최종적으로 각 샘플은 593비트 폭의 2진수 벡터로 변환됩니다. 

* 모든 벡터는 불량(0) 또는 정상(1)으로 레이블이 지정됩니다.

[여기](https://github.com/TadejMurovic/BNN_Deployment/blob/master/cybersecurity_dataset_unswb15.m)에서 Matlab 스크립트로 제공되는 Murovic과 Trost의 오픈 소스 구현에 따라 [Python 버전](dataloader_quantized.py)을 만들었습니다.

```bash
! wget -O unsw_nb15_binarized.npz https://zenodo.org/record/4519767/files/unsw_nb15_binarized.npz?download=1
```
```bash
#출력
Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.48.194, 188.185.45.92, ...
Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.
HTTP request sent, awaiting response... 301 MOVED PERMANENTLY
Location: /records/4519767/files/unsw_nb15_binarized.npz [following]
--2024-12-26 17:54:27--  https://zenodo.org/records/4519767/files/unsw_nb15_binarized.npz
Reusing existing connection to zenodo.org:443.
HTTP request sent, awaiting response... 200 OK
Length: 13391907 (13M) [application/octet-stream]
Saving to: ‘unsw_nb15_binarized.npz’

unsw_nb15_binarized 100%[===================>]  12.77M  1.45MB/s    in 11s     

2024-12-26 17:54:38 (1.17 MB/s) - ‘unsw_nb15_binarized.npz’ saved [13391907/13391907]

```
<br>

**.npz 아카이브에서 이진화된 숫자 배열을 추출하여 다음과 같이 PyTorch `TensorDataset`으로 래핑할 수 있습니다:**

```python
import numpy as np
from torch.utils.data import TensorDataset

def get_preqnt_dataset(data_dir: str, train: bool):
    unsw_nb15_data = np.load(data_dir + "/unsw_nb15_binarized.npz")
    if train:
        partition = "train"
    else:
        partition = "test"
    part_data = unsw_nb15_data[partition].astype(np.float32)
    part_data = torch.from_numpy(part_data)
    part_data_in = part_data[:, :-1]
    part_data_out = part_data[:, -1]
    return TensorDataset(part_data_in, part_data_out)

train_quantized_dataset = get_preqnt_dataset(".", True)
test_quantized_dataset = get_preqnt_dataset(".", False)
print("Samples in each set: train = %d, test = %s" % (len(train_quantized_dataset), len(test_quantized_dataset))) 
print("Shape of one input sample: " +  str(train_quantized_dataset[0][0].shape))
```
```bash
#출력
Samples in each set: train = 175341, test = 82332
Shape of one input sample: torch.Size([593])
```
<br>

#### 9.1. 이해하기

1. 데이터셋을 다운로드를 합니다. 형식은 `.npz`

2. `.npz` 파일를 로드하고, 이름 `Pytorch` 의 `TensorDataset` 객체로 변환하여 학습 및 테스트 데이터를 준비합니다.
    - 학습 및 테스트 파파티션을 설정합니다.

    - 데이터 타입 설정 

    - Numpy -> PyTorch Tensor

    - 입력 데이터와 출력 레이블을 분리
        - 입력 :`[,:-1]` 마지막 열 제외

        - 출력 :`[:,-1]` 마지막 열

3. Tensor Dataset을 생성합니다.

4. 학습 및 테스트 데이터 셋을 생성합니다.

5. 데이터셋이 잘 생성되었는지 확인합니다.

---
## 9.2. Set up DataLoader
---
**데이터로더 설정**

두 옵션 중 하나를 선택하면 이제 양자화된 데이터 세트에 액세스할 수 있습니다.

일괄적으로 쉽게 액세스할 수 있도록 데이터 세트를 PyTorch `DataLoader`로 래핑하겠습니다.

```python
from torch.utils.data import DataLoader, Dataset

batch_size = 1000

# dataset loaders
train_quantized_loader = DataLoader(train_quantized_dataset, batch_size=batch_size, shuffle=True)
test_quantized_loader = DataLoader(test_quantized_dataset, batch_size=batch_size, shuffle=False)    
```
<br>

```python
count = 0
for x,y in train_quantized_loader:
    print("Input shape for 1 batch: " + str(x.shape))
    print("Label shape for 1 batch: " + str(y.shape))
    count += 1
    if count == 1:
        break
```
```bash
#출력
Input shape for 1 batch: torch.Size([1000, 593])
Label shape for 1 batch: torch.Size([1000])
```
<br>

#### 9.2. 이해하기
1. `torch.utils.data` 모듈에서 `DataLoader` 및 `Dataset` 클래스를 가져옵니다.
    - `DataLoader` 는 데이터를 `Batch` 단위로 로드하고, 데이터셋의 반복을 처리합니다.

    - `Dataset` 은 데이터를 구조화된 형식으로 저장하고 엑세스하는 클래스입니다.

2. `DataLoader` 에 사용할 크기를 설정합니다.
    - 설정한 크기 만큼 묶어서 모델에 전달됩니다.

3. 학습 및 테스트 데이터로더를 생성합니다. 학습은 편향을 방지하기 위해 섞고 테스트는 섞지 않습니다.

4. 카운트 변수를 0으로 초기화 한 뒤 데이터를 확인하는 문이며 여기에서는 한 번만 확인합니다.

---
## 9.3. Define a PyTorch Device
---
**파이토치 장치 정의하기 **

GPU는 DNN 의 훈련 속도를 크게 높일 수 있습니다.

GPU가 사용 가능한지 확인하고 사용 가능한 경우 대상 장치로 정의합니다.

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Target device: " + str(device))
```
<br>

```bash
Target device: cuda
```
<br>

---
## 9.4. Define the Quantized MLP Model
---
**양자화된 MLP 모델 정의하기**

이제 양자화된 가중치와 활성화로 추론을 수행하도록 훈련할 MLP 모델을 정의하겠습니다.

이를 위해 [Brevitas](https://github.com/Xilinx/brevitas)에서 제공하는 양자화 인식 훈련(QAT) 기능을 사용할 것입니다.

MLP에는 64개의 뉴런이 있는 3개의 숨겨진 레이어와 단일 출력이 있는 최종 출력 레이어 등 총 4개의 완전 연결(FC) 레이어가 있으며, 모두 2비트 가중치를 사용합니다. 

2비트 양자화된 ReLU 활성화 함수를 사용하고, 각 FC 레이어와 활성화 사이에 일괄 정규화를 적용합니다.

다른 양자화 설정이나 토폴로지 파라미터로 실험하고 싶다면 이러한 모든 토폴로지 설정을 변수로 정의할 수 있습니다.

```python
input_size = 593      
hidden1 = 64      
hidden2 = 64
hidden3 = 64
weight_bit_width = 2
act_bit_width = 2
num_classes = 1    
```
<br>

이제 브레비타스에서 제공하는 레이어 프리미티브를 사용하여 MLP를 정의할 수 있습니다:

```python
from brevitas.nn import QuantLinear, QuantReLU
import torch.nn as nn

# Setting seeds for reproducibility
torch.manual_seed(0)

model = nn.Sequential(
      QuantLinear(input_size, hidden1, bias=True, weight_bit_width=weight_bit_width),
      nn.BatchNorm1d(hidden1),
      nn.Dropout(0.5),
      QuantReLU(bit_width=act_bit_width),
      QuantLinear(hidden1, hidden2, bias=True, weight_bit_width=weight_bit_width),
      nn.BatchNorm1d(hidden2),
      nn.Dropout(0.5),
      QuantReLU(bit_width=act_bit_width),
      QuantLinear(hidden2, hidden3, bias=True, weight_bit_width=weight_bit_width),
      nn.BatchNorm1d(hidden3),
      nn.Dropout(0.5),
      QuantReLU(bit_width=act_bit_width),
      QuantLinear(hidden3, num_classes, bias=True, weight_bit_width=weight_bit_width)
)

model.to(device)
```
<br>

MLP의 출력은 아직 정량화되지 않았습니다. 

MLP의 최종 출력이 분류를 나타내는 이진(0/1) 값이 되기를 원하지만, 지금까지는 단일 뉴런 FC 레이어만 출력으로 정의했습니다. 

네트워크를 훈련하는 동안 이 출력을 손실 기준의 일부로 시그모이드 함수에 전달하여 [더 나은 수치 안정성을 제공]합니다(https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html). 

나중에 네트워크 학습이 끝나면 마지막에 양자화 노드를 추가한 후 FINN으로 내보낼 것입니다.

#### 9.4. 이해하기

위 부분은 MLP 모델을 정의하는 부분입니다.

1. 변수를 특정 값으로 초기화를 진행합니다. 
    - 입력 593, 출력 클래스 수 1 (2진 분류)
2. `brevitas.nn` 모듈에 있는 `Linear` 와 `Relu` 클래스를 사용합니다.
    - PyTorch의 신경망 모듈인 torch.nn 을 사용합니다.

3. 코드를 실행할 때 동일한 결과를 보장하기 위해 `PyTorch` 의 난수 생성기에 시드를 설정합니다.

4. 모델을 구성합니다. 이때 `nn.Sequential` 을 사용하여 신경망의 계층을 순차적으로 정의합니다.
    - 입력 크기가 593 추력 크기가 64인 FC 레이어 층이며 2비트 양자화된 가중치를 사용합니다.
    
    - 배치 정규화를 사용하여 각 은닉층의 출력값을 정규화하여 학습 안정성을 향상시킴

    - 50% 확률로 뉴런을 비활성화하여 과적합을 방지함

    - 2비트로 양자화된 ReLU 활성화함수

    - 반복

    - 출력

5. 모델을 지정된 장치로 설정합니다. (CPU, GPU)

---
## 9.5. Define Train and Test Methods
---
**훈련 및 테스트 메서드 정의**

훈련 및 테스트 메서드는 전체 훈련 데이터가 모델에 공급될 때까지 각 반복마다 미리 정의된 새로운 훈련 데이터 배치를 모델에 공급하는 'DataLoader'를 사용합니다.

이 프로세스의 각 반복을 `epoch`라고 합니다.

```python  
def train(model, train_loader, optimizer, criterion):
    losses = []
    # ensure model is in training mode
    model.train()    
    
    for i, data in enumerate(train_loader, 0):        
        inputs, target = data
        inputs, target = inputs.to(device), target.to(device)
        optimizer.zero_grad()   
                
        # forward pass
        output = model(inputs.float())
        loss = criterion(output, target.unsqueeze(1))
        
        # backward pass + run optimizer to update weights
        loss.backward()
        optimizer.step()
        
        # keep track of loss value
        losses.append(loss.data.cpu().numpy()) 
           
    return losses
```
<br>

```python
import torch
from sklearn.metrics import accuracy_score

def test(model, test_loader):    
    # ensure model is in eval mode
    model.eval() 
    y_true = []
    y_pred = []
   
    with torch.no_grad():
        for data in test_loader:
            inputs, target = data
            inputs, target = inputs.to(device), target.to(device)
            output_orig = model(inputs.float())
            # run the output through sigmoid
            output = torch.sigmoid(output_orig)  
            # compare against a threshold of 0.5 to generate 0/1
            pred = (output.detach().cpu().numpy() > 0.5) * 1
            target = target.cpu().float()
            y_true.extend(target.tolist()) 
            y_pred.extend(pred.reshape(-1).tolist())
        
    return accuracy_score(y_true, y_pred)
```
<br>

#### 9.5. 이해하기 - 1 
1. train 클래스를 정의합니다.
    - model: 훈련할 모델.

    - train_loader: 훈련 데이터로더

    - optimizer: 모델 가중치를 업데이트하는 최적화 알고리즘.

    - criterion: 손실 함수로, 예측값과 실제값의 차이를 계산.

    - losses: 각 배치에서의 손실 값을 저장하기 위한 리스트.

2. `model.train()`으로 설정하여 모델을 훈련 모드로 설정합니다.
    - `Dropout` 및 `BatchNorm1d` 과 같은 레이어가 학습시 동작하게 설정합니다.

3. `for 문`을 통하여 GPU 또는 CPU 에 데이터를 전송합니다.
    - `optimizer.zero_grad()` 를 사용하여 이전 `Batch`에서 계산된 그래디언트를 초기화합니다.

4. 모델의 예측값을 출력하고 손실함수를 계산합니다.

5. 손실에 대한 그래디언트를 계산하고 모델의 가중치를 업데이트합니다.

6. 손실 값을 cpu로 옮긴 후 numpy 형식으로 변환하여 리스트에 추가합니다.

7. 각 배치의 손실 값을 반환합니다.

#### 9.5. 이해하기 - 2
1. test 클래스를 정의합니다.

2. `model.eval()` 으로 모델을 평가 모드로 설정합니다.

3. 실제 타깃 값을 저장할 리스트와 예측값을 저장할 리스트를 생성합니다.

4. `with torch.no_grad()`를 설정하여 평가 중에는 그래디언트를 계산하지 않게 합니다.
    - 이는 메모리 절약 및 속도향상에 도움이 됩니다.

5. `for 문`을 통해 정의를 합니다.
    - `output_orig` 은 모델의 출력값을 받습니다.(로그 확률)

    - `torch.sigmoid` 는 출력값을 확률로 변환합니다.

    - `pred` 는 확률이 0.5 이상이면 1 아니면 0으로 반환합니다.

    - `.extend` 를 사용하여 각 배치의 실제값과 예측값을 리스트에 추가합니다.

6. 예측과 실제값을 비교하여 정확도를 계산합니다.

---
## 9.6. Train the QNN - Option 1, slower
---
**QNN 훈련하기**

아래에서 두 가지 훈련 옵션을 제공합니다. 

처음부터 모델을 훈련하거나(느리게) 미리 훈련된 모델을 사용할 수 있습니다(빠르게).

첫 번째 옵션은 학습 프로세스의 작동 방식에 대한 더 많은 인사이트를 제공하는 반면, 두 번째 옵션은 정확도가 더 높을 가능성이 높습니다.


**Train the Model from Scratch **

MLP 학습을 시작하기 전에 몇 가지 하이퍼파라미터를 정의해야 합니다.

또한 에포크에 따른 손실 함수의 진화를 모니터링하려면 이를 위한 방법을 정의해야 합니다.


앞서 언급했듯이 훈련 단계에서는 시그모이드 함수를 적용하는 손실 기준(`BCEWithLogitsLoss`)을 사용합니다. 

테스트 단계에서는 0.5에서 시그모이드와 임계값을 수동으로 계산합니다.

```python
num_epochs = 10
lr = 0.001 

def display_loss_plot(losses, title="Training loss", xlabel="Iterations", ylabel="Loss"):
    x_axis = [i for i in range(len(losses))]
    plt.plot(x_axis,losses)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.show()
```
<br>

```python
# loss criterion and optimizer
criterion = nn.BCEWithLogitsLoss().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))
```
<br>

```python
import numpy as np
from sklearn.metrics import accuracy_score
from tqdm import tqdm, trange

# Setting seeds for reproducibility
torch.manual_seed(0)
np.random.seed(0)

running_loss = []
running_test_acc = []
t = trange(num_epochs, desc="Training loss", leave=True)

for epoch in t:
        loss_epoch = train(model, train_quantized_loader, optimizer,criterion)
        test_acc = test(model, test_quantized_loader)
        t.set_description("Training loss = %f test accuracy = %f" % (np.mean(loss_epoch), test_acc))
        t.refresh() # to show immediately the update           
        running_loss.append(loss_epoch)
        running_test_acc.append(test_acc)
```
```bash
#출력
Training loss:   0%|                                                                             | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1255: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)
  return super(Tensor, self).rename(names)
Training loss = 0.130141 test accuracy = 0.805422: 100%|████████████████████████████████| 10/10 [00:32<00:00,  3.25s/it]
```
<br>

```python
%matplotlib inline
import matplotlib.pyplot as plt

loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]
display_loss_plot(loss_per_epoch)
```
<br>

-이미지 첨부 output1


```python
acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]
display_loss_plot(acc_per_epoch, title="Test accuracy", ylabel="Accuracy [%]")
```
<br>

-이미지 첨부 output2


```python
test(model, test_quantized_loader)
```

```bash
#출력
0.805421950153039
```
<br>


```python
# Save the Brevitas model to disk
torch.save(model.state_dict(), "state_dict_self-trained.pth")
```
<br>

#### 9.6. 이해하기

이 코드는 정의한 모델에 대해 QNN 을 진행하는 과정입니다.
순서는 다음과 같게 진행이 됩니다.
1. 하이퍼파라미터 설정: 훈련에 필요한 하이퍼파라미터(에포크 수, 학습률 등)를 정의.
    - 총 훈련 에포크 수를 10으로 설정하고 학습률을 0.001로 정의합니다.

    - `display_loss_plot` 클래스를 정의합니다.
        - 훈련 중 손실 값을 시각화하며 손실 값이 에포크마다 어떻게 변화하는지 확인이 가능합니다.
        
2. 손실 함수 및 최적화 함수 설정: 손실 함수는 BCEWithLogitsLoss, 최적화 함수는 Adam을 사용.
    - 모델 훈련을 위해 두 손실 함수 및 최적화 함수를 사용합니다.

3. 훈련 루프: 모델을 훈련하고 각 에포크마다 손실과 정확도를 기록.
    - 정의 파트
        - `numpy` 
        - `accuracy_sorce` 로 예측 결과와 실제결과를 비교하여 정확도를 계산합니다.
        - `tqdm` 는 반복문 진행 상태를 시각적으로 보여주는 라이브러리입니다.
        - `trange` 는 진행항태를 표시합니다.
    - 매뉴얼 시드와 랜덤 시드를 사용하여 동일한 결과를 얻을 수 있게 합니다.

    - 훈련 손실과 테스트 정확도를 저장할 리스트를 생성합니다.

    - `trange` 를 사용하여 훈련 과정의 진행 상태를 보여줍니다.
        - 훈련 에포크 루프를 초기화 합니다.
    
    - 훈련 및 테스트를 반복합니다. tqdm 을 반복합니다.
        - `loss_epoch` 를 통해 훈련 데이터를 이용해 train 함수가 호출되고, 각 에포크에서의 훈련 손실을 loss_epoch로 저장합니다.
        
        - `test_acc` 를 통해 테스트 데이터를 이용해 test 함수가 호출되고, 각 에포크에서의 테스트 정확도를 test_acc로 저장합니다.
        
        - `t.set_descriptioncy`를 통해 tqdm 진행 상태 바에 훈련 손실과 테스트 정확도를 실시간으로 표시합니다.

        - `t.refresh()`를 통해 상태 바를 즉시 갱신하여 진행 상태를 즉시 표시합니다.

    - 훈련 손실 및 테스트 정확도를 기록합니다.

4. 결과 시각화: 훈련 손실과 테스트 정확도를 그래프로 시각화합니다.
    - `%matplotlib inline` 으로 주피터 노트북에서 그래프를 바로 시각화를 합니다.

    - 훈련 손실 그래프를 그립니다.

    - `acc_per_epoch` 로 테스트 정확도 그래프를 그립니다.


5. 최종 테스트: 훈련이 완료된 후 모델을 테스트 데이터로 평가.
    - test(model, test_quantized_loader)를 사용하여 평가를 합니다.

6. 모델 저장: 훈련된 모델을 디스크에 저장.
    - torch 로 훈련된 모델을 저장합니다.


---
## 9.7. Train the QNN - Option 2, faster
---
**사전 학습된 파라미터 로드 **

처음부터 학습하는 대신 여기에서 제공하는 사전 학습된 파라미터를 사용할 수도 있습니다.

이러한 매개변수를 사용하면 테스트 정확도가 최대 91.9%에 달합니다.

```python
import os
import torch

# Make sure the model is on CPU before loading a pretrained state_dict
model = model.cpu()

# Load pretrained weights
trained_state_dict = torch.load(model_dir + "/state_dict.pth")["models_state_dict"][0]

model.load_state_dict(trained_state_dict, strict=False)
```
```bash
#출력
<All keys matched successfully>
```
<br>

```python
# Move the model back to it's target device
model.to(device)

# Test for accuracy
test(model, test_quantized_loader)
```
```bash
#출력
0.9188772287810328
```
<br>

**이러한 파라미터가 처음부터 학습하는 것보다 더 나은 정확도를 제공하는 이유는 무엇인가요? 

토폴로지와 양자화가 고정되어 있더라도 주어진 데이터 세트에서 좋은 정확도를 얻으려면 [*하이퍼파라미터 튜닝*](https://towardsdatascience.com/hyperparameters-optimization-526348bb8e2d)과 장시간의 학습 실행이 필요합니다. 

위의 '처음부터 트레이닝' 예는 간단한 예시일 뿐이며, *하이퍼파라미터 튜닝을 위해 [determined.ai](https://determined.ai/) 플랫폼을 사용하여 장기간 트레이닝을 실행하면 사전 트레이닝된 파라미터를 얻을 수 있습니다.*

---
## 9.8. Network Surgery Befor Export - 1
---
**내보내기 전 네트워크 수술**

때로는 내보내기 전에 훈련된 네트워크를 일부 변경하는 것이 바람직할 때가 있습니다(이를 일반적으로 “Network surgery”이라고 함). 

이는 모델에 따라 다르며 일반적으로는 필요하지 않지만, 이 경우에는 FINN에서 더 나은 결과를 얻기 위해 몇 가지 변경을 하고자 합니다.

```python
# Move the model to CPU before surgery
model = model.cpu()
```
<br>

먼저 입력을 패딩하는 것부터 시작하겠습니다. 

입력 벡터는 593비트이므로 593은 소수이므로 첫 번째 레이어의 폴딩(병렬화)이 약간 까다로울 수 있습니다.

따라서 첫 번째 레이어의 가중치 행렬을 0값 열 7개로 패딩하여 대신 입력 크기 600으로 작업하겠습니다.

수정된 네트워크를 사용할 때도 마찬가지로 600비트로 패딩된 입력을 제공할 것입니다.

```python
from copy import deepcopy

modified_model = deepcopy(model)

W_orig = modified_model[0].weight.data.detach().numpy()
W_orig.shape
```
```bash
#출력
(64,593)
```
<br>

```python
import numpy as np

# pad the second (593-sized) dimensions with 7 zeroes at the end
W_new = np.pad(W_orig, [(0,0), (0,7)])
W_new.shape
```
```bash
#출력
(64, 600)
```
<br>

```python
modified_model[0].weight.data = torch.from_numpy(W_new)
modified_model[0].weight.shape
```
```bash
#출력
torch.Size([64, 600])
```
<br>

#### 9.8. 이해하기 

1. 모델을 GPU 에서 CPU로 변경합니다.

2. `copy` 를 사용하여 기존 객체와 독립적으로 동작하는 새 객체를 생성합니다.
    - `modified_model = deepcopy(model)` 를 사용하여 원본 모델을 수정하지 않고 복사본에서 작업을 진행합니다.

    - `w_orig` 를 통해서 모델의 첫 번째 레이어의 가중치를 추출, 가중치를 Numpy 배열로 변환 등 작업을 진행합니다.

3. `W_new` 를 통해서 배열의 특정 차원에 패딩을 추가하는데 출력 크기(첫 번째 차원)은 변경하지 않고, 입력 크기(두 번째 크기)만 변경하여 오른쪽에 7개의 0을 넣어 패딩을 진행합니다.
    - `w_new.shape` 을 통해서 패딩이 잘 적용되었는지 확인합니다.

4. `modified_model[0].weight.data` 를 통하여 Numpy 배열을 PyTorch 텐서로 변경하고 업데이트를 합니다.
    - 수정된 가중치의 크기를 `.shape` 을 통하여 확인합니다.

---
## 9.9. Network Surgery Befor Export -2 
---
다음으로 예상되는 입력/출력 범위를 수정하겠습니다.

**FINN**에서는 **이진 {0, 1} 값 대신 바이폴라 {-1, +1}로 작업하는 것을 선호**합니다. 

이를 위해 다음과 같이 전/후처리를 처리하는 “wrapper” 모델을 만들겠습니다:

* 입력 측에서는 (x + 1) / 2로 사전 처리하여 들어오는 {-1, +1} 입력을 훈련된 네트워크에 익숙한 {0, 1} 입력에 매핑합니다.
스칼라를 곱하거나 더하기만 하기 때문에 이러한 연산은 FINN으로 [*간소화*](https://finn.readthedocs.io/en/latest/nw_prep.
html#streamlining-transformations)할 수 있으며 추가 비용 없이 구현할 수 있습니다.

* 출력 측에서는 0 이하의 모든 것을 -1로, 0 이상의 모든 것을 +1로 매핑하는 이진 양자화기를 추가할 것입니다. 
이는 앞서 사용한 시그모이드와 본질적으로 동일한 동작이지만, 출력이 2진법이 아닌 바이폴라라는 점이 다릅니다.

```python
from brevitas.nn import QuantIdentity


class CybSecMLPForExport(nn.Module):
    def __init__(self, my_pretrained_model):
        super(CybSecMLPForExport, self).__init__()
        self.pretrained = my_pretrained_model
        self.qnt_output = QuantIdentity(
            quant_type='binary', 
            scaling_impl_type='const',
            bit_width=1, min_val=-1.0, max_val=1.0)
    
    def forward(self, x):
        # assume x contains bipolar {-1,1} elems
        # shift from {-1,1} -> {0,1} since that is the
        # input range for the trained network
        x = (x + torch.tensor([1.0]).to(x.device)) / 2.0  
        out_original = self.pretrained(x)
        out_final = self.qnt_output(out_original)   # output as {-1,1}     
        return out_final

model_for_export = CybSecMLPForExport(modified_model)
model_for_export.to(device)
```
<br>

```python
def test_padded_bipolar(model, test_loader):    
    # ensure model is in eval mode
    model.eval() 
    y_true = []
    y_pred = []
   
    with torch.no_grad():
        for data in test_loader:
            inputs, target = data
            inputs, target = inputs.to(device), target.to(device)
            # pad inputs to 600 elements
            input_padded = torch.nn.functional.pad(inputs, (0,7,0,0))
            # convert inputs to {-1,+1}
            input_scaled = 2 * input_padded - 1
            # run the model
            output = model(input_scaled.float())
            y_pred.extend(list(output.flatten().cpu().numpy()))
            # make targets bipolar {-1,+1}
            expected = 2 * target.float() - 1
            expected = expected.cpu().numpy()
            y_true.extend(list(expected.flatten()))
        
    return accuracy_score(y_true, y_pred)
```
<br>

```python
test_padded_bipolar(model_for_export, test_quantized_loader)
```
```bash
#출력
0.9188772287810328
```
<br>

#### 9.9. 이해하기
1. `brevitas.nn.QuantIdenty` 

2. `CybSecMLPForExport` 클래스를 정의합니다. 

---
## 9.10. Export to QONNX and Conversion to FINN-ONNX 
---
**QONNX로 내보내기 및 FINN-ONNX로 변환**

[ONNX](https://onnx.ai/)는 머신 러닝 모델을 표현하기 위해 만들어진 개방형 포맷으로, FINN 컴파일러는 ONNX 모델을 입력으로 기대합니다. 

이제 네트워크를 ONNX로 내보내어 다음 노트북의 FINN에서 가져와서 사용하겠습니다. 

FINN에 사용되는 특정 ONNX 표현은 표준 ONNX와 다르며, 이에 대한 자세한 내용은 [여기](https://finn.readthedocs.io/en/latest/internals.html#intermediate-representation-finn-onnx)에서 확인할 수 있습니다.

아래에서 **Brevitas에서 학습된 네트워크를 FINN과 호환되는 ONNX 표현(QONNX)으로 내보내는 방법**을 확인할 수 있습니다.

**QONNX는 Brevitas에서 내보낼 수 있는 형식**이며, 이를 **FINN 컴파일러에 공급하려면 컴파일러가 작동하는 중간 표현인 FINN-ONNX 형식으로 변환**해야 합니다.

**FINN-ONNX 형식의 변환은 FINN 컴파일러 변환**이며, 이를 **모델에 적용하기 위해서는 [ModelWrapper](https://finn.readthedocs.io/en/latest/internals.html#modelwrapper)로 래핑**해야 합니다.

이것은 모델을 더 쉽게 작업할 수 있도록 몇 가지 도우미 함수를 제공하는 ONNX 모델을 감싸는 래퍼입니다.

그런 다음 변환 함수를 호출하여 FINN-ONNX 형식의 모델을 얻을 수 있습니다.

```python
from brevitas.export import export_qonnx
from qonnx.util.cleanup import cleanup as qonnx_cleanup
from qonnx.core.modelwrapper import ModelWrapper
from qonnx.core.datatype import DataType
from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN

ready_model_filename = model_dir + "/cybsec-mlp-ready.onnx"
input_shape = (1, 600)

# create a QuantTensor instance to mark input as bipolar during export
input_a = np.random.randint(0, 1, size=input_shape).astype(np.float32)
input_a = 2 * input_a - 1
scale = 1.0
input_t = torch.from_numpy(input_a * scale)

#Move to CPU before export
model_for_export.cpu()

# Export to ONNX
export_qonnx(
    model_for_export, export_path=ready_model_filename, input_t=input_t
)

# clean-up
qonnx_cleanup(ready_model_filename, out_file=ready_model_filename)

# ModelWrapper
model = ModelWrapper(ready_model_filename)
# Setting the input datatype explicitly because it doesn't get derived from the export function
model.set_tensor_datatype(model.graph.input[0].name, DataType["BIPOLAR"])
model = model.transform(ConvertQONNXtoFINN())
model.save(ready_model_filename)

print("Model saved to %s" % ready_model_filename)
```
```bash
#출력
Model saved to /home/lsh/FPGA/finn/notebooks/end2end_example/cybersecurity/cybsec-mlp-ready.onnx
/home/lsh/FPGA/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 14. Thus the transformation may fail or return incomplete results.
  warnings.warn(
```
<br>

#### 9.10. 이해하기
1. ONNX는 머신 러닝 모델을 표현하기 위한 포맷

2. Brevitas 에서 학습된 네트워크를 FINN과 호환되는 QONNX로 내보냄
    - QONNX는 Brevitas 에서 내보낼 수 있는 형식임

3. FINN 컴파일러에 공급하려면 FINN-ONNX 형식으로 변환해야함
    - 이는 FINN 컴파일러 변환이며 이를 모델에 적용하기 위해서는 `ModelWrapper` 로 래핑해야함

---
## 9.11. View the Exported ONNX in Netron
---
**네트론에서 내보낸 ONNX 보기**

신경망용 시각화 도구이자 네트워크 속성을 대화형으로 조사할 수 있는 [Netron](https://github.com/lutzroeder/netron)으로 내보낸 ONNX 모델을 살펴봅시다.

예를 들어 개별 노드를 클릭하고 속성을 볼 수 있습니다.

특히 주목할 만한 사항
* 입력 텐서 “0”에는 `quantization: finn_datatype: BIPOLAR`로 주석 처리됩니다.

* 입력 전처리(x + 1)/2는 네트워크의 일부로 내보내집니다(초기 `Add` 및 `Div` 레이어).

* 브레비타스 `QuantLinear` 레이어는 `MatMul`로 ONNX로 내보냅니다. 패딩된 버전을 내보냈습니다. 첫 번째 MatMul 노드의 가중치 매개변수 모양은 600x64입니다.

* MatMul 노드의 가중치 매개변수(두 번째 입력)에는 `quantization: finn_datatype: INT2`로 주석 처리됩니다.

* 양자화된 활성화는 `domain=qonnx.custom_op.general`을 사용하여 `MultiThreshold` 노드로 내보냅니다.

* 최종 바이폴라 출력을 생성하기 위해 임계값이 0인 최종 `MultiThreshold` 노드가 있습니다(이는 `CybSecMLPForExport`의 `qnt_output`입니다).







#### 9.11. 이해하기

-----