---
title: "[2024반도체해커톤] 11. FINN 예제 이해하기 Cybersecurity 3장 - Build accelerator with finn"
date: 2025-01-03 12:12:00 +09:00
categories: [Project, 2024_2 반도체해커톤,]
tags:
  [
    verilog,
    systemverilog,
    Vivado,
    Vitis,
    Xilinx,
    FINN,
    Bretivas
  ]
---

## 환경사항
사용하고 있는 환경은 다음과 같다.

| 이름                      | 버전       | 기타 정보 |
| :-------------------------------| :-----------------| :-------: |
| Vivado			| 2023.2		| O	|
| Vitis			| 2023.2		| O	|
| WSL2			| 5.15.167.4	| O	|
| Ubuntu			| 20.04.06	| O	|
| Docker Desktop		|		| O	|


## 목차 
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-0.WLS2-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%ED%95%98%EB%93%9C%EC%9B%A8%EC%96%B4-%EC%9E%A5%EB%B9%84-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0/">0. WSL2 환경에서 하드웨어 장비 연결하기<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-1.%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0/">1. 환경 설정하기<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-2.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Basics-1%EC%9E%A5-How-to-work-with-onnx/">2. FINN 예제 이해하기 Basics 1장 - How to work with onnx<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-3.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Basics-2%EC%9E%A5-Brevitas-netowrk-import-via-QONNX/">3. FINN 예제 이해하기 Basics 2장 - Brevitas netowrk import via QONNX<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-4.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Advanced-1%EC%9E%A5-Custom-analysis-pass/">4. FINN 예제 이해하기 Advanced 1장 - Custom analysis pass<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-5.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Advanced-2%EC%9E%A5-transformation-passes/">5. FINN 예제 이해하기 Advanced 2장 - Transformation passes<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-6.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Advanced-3%EC%9E%A5-custom-op/">6. FINN 예제 이해하기 Advanced 3장 - Custom op<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-7.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Advanced-4%EC%9E%A5-Folding/">7. FINN 예제 이해하기 Advanced 4장 - Folding<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-8.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Advanced-5%EC%9E%A5-Advanced-builder-settings/">8. FINN 예제 이해하기 Advanced 5장 - Advanced builder settings<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-9.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Cybersecurity-1%EC%9E%A5-Train-mlp-with-brevitas/">9. FINN 예제 이해하기 Cybersecurity 1장 - Train mlp with brevitas<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-10.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Cybersecurity-2%EC%9E%A5-Import-into-finn-and-verify/">10. FINN 예제 이해하기 Cybersecurity 2장 - Import into finn and verify<br>
<a href="https://hyeokls.github.io/posts/2024%EB%B0%98%EB%8F%84%EC%B2%B4%ED%95%B4%EC%BB%A4%ED%86%A4-11.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-Cybersecurity-3%EC%9E%A5-Build-accelerator-with-finn/">11. FINN 예제 이해하기 Cybersecurity 3장 - Build accelerator with finn<br>


# 이번 챕터에서는 무엇을 했나요?
이번은 `cybersecurity`챕터에서의 과정을 공부를 진행하였습니다.

---
## 11.0.1. Train a Quantized MLP on UNSW-NB15 with Brevitas
---
# 스트리밍 데이터 흐름 가속기 구축하기

**중요: 이 노트북은 해당 노트북에서 생성된 모델을 사용하기 때문에 1-train-mlp-with-brevitas 노트북에 의존합니다. 따라서 이 노트북을 실행하기 전에 필요한 .onnx 파일이 생성되었는지 확인하세요.**

이 노트북에서는 FINN 컴파일러를 사용하여 사이버 보안 작업을 위해 양자화된 MLP에서 스트리밍 데이터 흐름 아키텍처를 갖춘 FPGA 가속기를 생성합니다. 

이러한 아키텍처의 핵심 아이디어는 왼쪽 그림과 같이 각 레이어에 비례하는 양의 컴퓨팅 리소스를 할당하여 레이어 내뿐만 아니라 레이어 간에도 병렬화하는 것입니다.

일반적인 개념에 대한 자세한 내용은 [FINN](https://arxiv.org/pdf/1612.07119) 및 [FINN-R](https://dl.acm.org/doi/pdf/10.1145/3242897) 백서에서 확인할 수 있습니다.

이는 각 레이어를 Vivado HLS 설명에 매핑하고, 각 레이어의 구현을 적절한 수준으로 병렬화하고, 온칩 FIFO를 사용하여 레이어를 연결하여 전체 가속기를 생성함으로써 수행됩니다.

이러한 구현은 성능과 유연성 간에 좋은 균형을 제공하지만 수작업으로 구축하는 것은 어렵고 시간이 많이 소요됩니다.

이때 FINN 컴파일러를 사용하면 원하는 처리량에 맞게 ONNX 설명에서 스트리밍 데이터 흐름 가속기를 빌드할 수 있습니다.

## 11.0.2. Outline
1. [Introduction to  `build_dataflow` Tool]
2. [Understanding the Build Configuration: `DataflowBuildConfig`]  
    2.1.[Output Products]  
    2.2.[Configuring the Board and FPGA Part]  
    2.3 [Configuring the Performance] 
4. [Launch a Build: Only Estimate Reports]
5. [Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance]
6. [(Optional) Launch a Build: PYNQ Bitfile and Driver]
7. [(Optional) Run on PYNQ board]
---
## 11.0.3. Introduction to build_dataflow Tool
---
**빌드_데이터흐름` 도구 소개**

버전 0.5b부터 FINN 컴파일러에는 `build_dataflow` 도구가 있습니다.

파이썬 스크립트에서 필요한 모든 변환을 설정해야 했던 이전 버전에 비해 데이터 흐름 아키텍처 생성을 더 쉽게 실험할 수 있습니다.

핵심 아이디어는 관련 빌드 정보를 구성 `dict`로 지정하여 데이터 흐름 빌드를 수행하는 데 필요한 모든 단계를 호출하는 것입니다.

이 설정은 [Command line](https://finn-dev.readthedocs.io/en/latest/command_line.html)에서 호출하거나 단일 Python 함수 호출로 호출할 수 있습니다.

이 노트북에서는 Python 함수 호출을 사용하여 빌드를 호출하여 Jupyter 노트북 내부에 머물도록 하겠지만, './run-docker.sh build_dataflow` 및 './run-docker.sh build_custom` 명령줄 진입점으로도 여기서 수행하는 작업을 자유롭게 재현하여 실험해 보시기 바랍니다. 

---
## 11.0.4. Understanding the Build configuration: DataflowBuildConfig
---
**빌드 구성 이해: `DataflowBuildConfig**

빌드 구성은 `finn.builder.build_dataflow_config.DataflowBuildConfig`의 인스턴스로 지정됩니다.

이 구성은 지속성을 위해 JSON 파일로 직렬화하거나 직렬화 해제할 수 있는 Python [`dataclass`](https://docs.python.org/3/library/dataclasses.html)이지만 여기서는 Python으로만 설정하겠습니다.

구성에는 빌드의 다양한 측면을 사용자 정의할 수 있는 많은 옵션이 있지만 이 노트북에서는 그 중 몇 가지 옵션만 다루겠습니다. 모든 구성 옵션에 대한 자세한 내용은 [FINN API 문서](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.DataflowBuildConfig)에서 확인할 수 있습니다.

데이터 흐름 빌드 구성`의 몇 가지 멤버를 살펴보겠습니다:

**Output Products**

빌드는 다양한 출력을 생성할 수 있으며, 그 중 일부는 시간이 오래 걸릴 수 있습니다(예: 대규모 네트워크의 비트 파일 합성). 

새 가속기를 생성하고 다양한 성능 옵션을 탐색하는 작업을 처음 시작할 때는 비트파일까지 만들고 싶지 않을 수 있습니다.

따라서 처음에는 예상 보고서만 출력 제품으로 선택할 수 있습니다.

점차적으로 셸에 통합된 전체 가속기를 구축할 수 있을 만큼 설계에 만족할 때까지 이후 단계부터 출력 제품을 생성할 수 있습니다.

에 의해 출력 제품이 제어됩니다:

* 생성_출력`: 빌드에서 생성할 출력 제품 목록([`finn.builder.build_dataflow_config.DataflowOutputType`](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.DataflowOutputType) 유형). 사용 가능한 옵션은 다음과 같습니다:
    - `ESTIMATE_REPORTS`: 합성 없이 레이어별 및 전체 네트워크에 대한 예상 리소스 및 성능을 보고합니다.
    - `STITCHED_IP`: 다른 Vivado IPI 또는 RTL 설계에 통합할 수 있는 스트림 인 스트림 아웃 IP 설계 생성
    - 'RTLSIM_PERFORMANCE' : PyVerilator를 사용하여 `STITCHED_IP` 설계의 성능/지연 시간 테스트 수행
    - OOC_SYNTH` : `STITCHED_IP` 디자인에서 컨텍스트 외 합성(주변 시스템 없이 가속기 자체만)을 실행하여 합성 후 FPGA 리소스 및 달성 가능한 클럭 주파수를 얻습니다.
    - `BITFILE`: 가속기를 셸에 통합하여 독립형 비트 파일을 생성합니다.
    - `PYNQ_DRIVER` : 가속기를 실행하는 데 사용할 수 있는 PYNQ 파이썬 드라이버를 생성합니다.
    - `DEPLOYMENT_PACKAGE` : 대상 FPGA 플랫폼에 복사할 준비가 된 `BITFILE` 및 `PYNQ_DRIVER` 출력이 있는 폴더를 생성합니다.
* `output_dir`: 위에서 생성된 모든 빌드 출력이 기록될 디렉토리입니다.
* `steps`: 미리 정의된(또는 사용자 정의된) 빌드 단계의 목록입니다. 합성을 하지 않고 추정에 필요한 단계만 실행하려면 `build_dataflow_config.estimate_only_dataflow_steps`를 사용하고, 그렇지 않은 경우 기본값인 `build_dataflow_config.default_build_dataflow_steps`를 사용하세요. 기본 단계 목록은 [여기](https://finn.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.default_build_dataflow_steps) 문서에서 확인할 수 있습니다.

**보드 및 FPGA 부품 구성하기**

* `fpga_part`: 합성에 사용할 자일링스 FPGA 부품으로, 아래 `board`에서 유추할 수 있도록 지정하지 않거나 컨텍스트 외 합성을 위해 명시적으로 지정할 수 있습니다.
* `board`: 셸에 통합된 가속기 생성을 위한 타겟 Xilinx Zynq 또는 Alveo 보드. 가능한 보드 목록은 [이 파일](https://github.com/Xilinx/finn-base/blob/dev/src/finn/util/basic.py#L41)의 `pynq_part_map` 및 `alveo_part_map` 딕셔너리를 참조하세요.
* `shell_flow_type`: 대상 [셸 흐름 유형](https://finn-dev.readthedocs.io/en/latest/source_code/finn.builder.html#finn.builder.build_dataflow_config.ShellFlowType), FINN 설계가 셸에 통합된 전체 비트파일을 생성하는 데만 필요합니다(따라서 `BITFILE`이 선택된 경우에만 필요). 


**성능 구성하기**

생성된 데이터 흐름 가속기의 성능(및 그에 따른 FPGA 리소스 사용량)은 두 가지 방법으로 구성할 수 있습니다:

1) (기본) 목표 성능을 설정하고 컴파일러가 노드별 병렬화 설정을 알아내도록 합니다.

2) (고급) 각 계층에 대한 병렬화 정도(및 기타 하드웨어 옵션)를 나열하는 별도의 .json을 `folding_config_file`로 지정합니다.

이 노트북에서는 설정이 필요한 기본 접근 방식만 다룹니다:

* target_fps`: 초당 프레임 단위의 목표 추론 성능. 특정 레이어 제약이나 FPGA의 리소스 제한으로 인해 목표에 도달하지 못할 수도 있습니다. 
* synth_clk_period_ns`: Vivado 합성을 위한 목표 클럭 주파수(나노초 단위). 예: `synth_clk_period_ns=5.0`은 200MHz 클럭을 목표로 합니다. FPGA 부품 및 설계 복잡도에 따라 목표 클럭 주기를 달성하지 못할 수도 있습니다.

---
## 11.1. Launch a Build: Only Estimate Reports - 1
---
**빌드 시작: 견적 보고서만**

먼저 합성이 필요 없는 예상 보고서만 생성하는 빌드를 실행해 보겠습니다.

아래에서 두 가지를 주목하세요.

`generate_outputs`에 `ESTIMATE_REPORTS`만 포함되는 방식과 `steps`에 `ESTIMATE_ONLY_DATAFLOW_STEPS` 값을 사용하는 방식입니다.

이렇게 하면 분석 모델에서 빠른 추정치를 제공하기 위해 HLS 합성과 같은 단계를 건너뜁니다.

```python
import finn.builder.build_dataflow as build
import finn.builder.build_dataflow_config as build_cfg
import os
import shutil

model_dir = os.environ['FINN_ROOT'] + "/notebooks/end2end_example/cybersecurity"
model_file = model_dir + "/cybsec-mlp-ready.onnx"

estimates_output_dir = "output_estimates_only"

#Delete previous run results if exist
if os.path.exists(estimates_output_dir):
    shutil.rmtree(estimates_output_dir)
    print("Previous run results deleted!")


cfg_estimates = build.DataflowBuildConfig(
    output_dir          = estimates_output_dir,
    mvau_wwidth_max     = 80,
    target_fps          = 1000000,
    synth_clk_period_ns = 10.0,
    fpga_part           = "xc7z020clg400-1",
    steps               = build_cfg.estimate_only_dataflow_steps,
    generate_outputs=[
        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,
    ]
)
```
```bash

```
<br>

#### 11.1. 이해하기 중요
1. `finn.builder` 를 사용하여 빌드를 구성합니다.

2. 디렉토리 관련하여 정의를 해줍니다.

3. `if` 문을 통하여 이전의 실행한 결과 디렉토리가 있다면 삭제합니다.

4. `cfg_estimates` 를 사용하여 기본 설정을 진행합니다. 여러가지 들이 있지만 사용된 것들은 다음과 같습니다.
  - output_dir : 최종 빌드 출력이 쓰여질 디렉토리를 의미합니다.

  - mvau_wwidth_max(옵션) : 병렬화 속성을 탐색하는 동안 PE 당 MVAU 스트림의 최대 폭을 제어하여 `target_fps`에 도달합니다.
  `target_fps`가 지정된 경우에만 관련이 있습니다.

  - target_fps(옵션) : 초당 프레임 단위의 목표 추론 성능을 뜻하며 특정 레이너 제약이나 FPGA의 리소스 제한으로 인해 목표에 도달하지 못할 수도 있습니다.
    - 병렬화 속성이 `folding_config_file`의 일부로 지정되어 있는 경우 여기에서 `target_fps` 설정을 재정의합니다.

  - synth_clk_period_ns : `vivado` 합성을 위한 목표 클럭 주파수(ns) 
    - ex : 5.0 은 200MHz 클럭을 목표로 합니다. 여기서 10.0은 100Mhz 를 목표로 합니다.

  - fpga_part : 대상 자일링스 부품이며 보드가 지정되지 않은 경우에 필요합니다. 

  - steps : 주어진 경우 목록에 있는 단계만 실행합니다. 그렇지 않은 경우 기본 단계를 실행합니다. 

  - generate_outputs : 빌드 플로우에서 생성할 출력이며 출력할 수 있는 유형음 다음과 같습니다.
    - BITFILE :비트파일

    - DEPLOYMENT_PACKAGE : 배포 패키지

    - ESTIMATE_REPORTS

    - OOC_SYNTH= 'out_of_context_synth'

    - PYNQ_DRIVER= 'pynq_driver'
    
    - RTLSIM_PERFORMANCE= 'rtlsim_performance'

    - STITCHED_IP= 'stitched_ip'



---
## 11.2. Launch a Build: Only Estimate Reports - 2
---
```python
%%time
build.build_dataflow_cfg(model_file, cfg_estimates)
```
```bash
Building dataflow accelerator from /home/lsh/FPGA/finn/notebooks/end2end_example/cybersecurity/cybsec-mlp-ready.onnx
Intermediate outputs will be generated in /tmp/finn_dev_lsh
Final outputs will be generated in output_estimates_only
Build log is at output_estimates_only/build_dataflow.log
Running step: step_qonnx_to_finn [1/10]
Running step: step_tidy_up [2/10]
Running step: step_streamline [3/10]
Running step: step_convert_to_hw [4/10]
Running step: step_create_dataflow_partition [5/10]
Running step: step_specialize_layers [6/10]
Running step: step_target_fps_parallelization [7/10]
Running step: step_apply_folding_config [8/10]
Running step: step_minimize_bit_width [9/10]
Running step: step_generate_estimate_reports [10/10]
Completed successfully
CPU times: user 863 ms, sys: 911 ms, total: 1.77 s
Wall time: 628 ms
```
<br>

#### 11.2. 이해하기 
`finn.builder.build_dataflow.build_dataflow_cfg(model_filename, cfg: DataflowBuildConfig)` 형식으로 사용되며 주어진 구성을 사용하여 데이터 플로우 가속기를 최적으로 빌드합니다.

파라미터는 다음과 같습니다.

- model_filename : 빌드할 ONNX 모델 파일 이름

- cfg : 빌드 구성

---
## 11.3. Launch a Build: Only Estimate Reports - 3
---
```python
assert os.path.exists(estimates_output_dir + "/report/estimate_network_performance.json")
```
<br>

이제 이 빌드에서 생성된 결과물을 살펴보겠습니다. 

산출물 디렉토리 아래를 살펴보면 생성된 예상 보고서가 있는 하위 폴더를 찾을 수 있습니다.

```python
! ls {estimates_output_dir}
```
```bash
auto_folding_config.json  report
build_dataflow.log	  template_specialize_layers_config.json
intermediate_models	  time_per_step.json
```
<br>

```python
! ls {estimates_output_dir}/report
```
```bash
estimate_layer_config_alternatives.json  estimate_network_performance.json
estimate_layer_cycles.json		 op_and_param_counts.json
estimate_layer_resources.json
```
<br>

다양한 보고서가 .json 파일로 생성된 것을 확인할 수 있습니다. 우선 `estimate_network_performance.json`의 내용을 살펴봅시다.

여기에서는 성능과 지연 시간에 대한 분석 추정치를 확인할 수 있습니다.

```python
! cat {estimates_output_dir}/report/estimate_network_performance.json
```
```bash
{
  "critical_path_cycles": 252,
  "max_cycles": 64,
  "max_cycles_node_name": "MVAU_hls_1",
  "estimated_throughput_fps": 1562500.0,
  "estimated_latency_ns": 2520.0
}
```
<br>

#### 11.3. 이해하기
1. 첫 번째는 출력물들에 대해 설명을 합니다.

2. 두 번째는 `report` 폴더에 있는 `.json` 파일들을 내열합니다.

3. 세 번째는 생성된 파일 중 `estimate_network_performance.json` 파일의 내용이며 네트워크 성능에 관련된 내용입니다.
  - "critical_path_cycles": 지연경로에 소요된 사이클 수를 의미합니다.

  - "max_cycles": 단일 노드에서 가장 많은 사이클을 소요한 값을의미하며 즉, 가장 느린 노드의 사이클 수 입니다.
  
  - "max_cycles_node_name": "MVAU_hls_1" : 위에 해당하는 부분의 노드 이름입니다.
  
  - "estimated_throughput_fps": 예측된 처리량
  
  - "estimated_latency_ns": 네트워크의 총 추정 지연 시간


---
## 11.4. Launch a Build: Only Estimate Reports - 4
---
이러한 보고서는 모두 .json 파일이므로 추가 처리를 위해 Python으로 쉽게 로드할 수 있습니다.

이는 FINN을 기반으로 자체 디자인 자동화 도구를 구축하는 경우 유용할 수 있습니다.

도우미 함수를 정의하고 `estimate_layer_cycles.json` 보고서를 살펴봅시다.

```python
import json
def read_json_dict(filename):
    with open(filename, "r") as f:
        ret = json.load(f)
    return ret
```
<br>

```python
read_json_dict(estimates_output_dir + "/report/estimate_layer_cycles.json")
```
```bash
{'MVAU_hls_0': 60, 'MVAU_hls_1': 64, 'MVAU_hls_2': 64, 'MVAU_hls_3': 64}
```
<br>
 
여기에서 각 계층의 예상 클럭 사이클 수를 확인할 수 있습니다. 

이 모든 레이어는 병렬로 실행되며 가장 느린 레이어가 전체 신경망의 전체 처리량을 결정한다는 점을 기억하세요. 

FINN은 각 레이어가 모두 비슷한 수의 사이클이 걸리도록 병렬화를 시도하며, `target_fps`를 충족하는 데 필요한 해당 사이클 수보다 적습니다.

또한 모든 레이어 사이클 추정치를 합산하면 전체 네트워크의 전체 지연 시간에 대한 추정치를 얻을 수 있습니다. 

마지막으로 `estimate_layer_resources.json` 보고서에서 레이어별 리소스 추정치를 확인할 수 있습니다:

```python
read_json_dict(estimates_output_dir + "/report/estimate_layer_resources.json")
```
```bash
{'MVAU_hls_0': {'BRAM_18K': 36,
  'BRAM_efficiency': 0.11574074074074074,
  'LUT': 6741,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_1': {'BRAM_18K': 4,
  'BRAM_efficiency': 0.1111111111111111,
  'LUT': 1149,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_2': {'BRAM_18K': 4,
  'BRAM_efficiency': 0.1111111111111111,
  'LUT': 1148,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_3': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.006944444444444444,
  'LUT': 316,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'total': {'BRAM_18K': 45.0, 'LUT': 9354.0, 'URAM': 0.0, 'DSP': 0.0}}
```
<br>

이 특정 보고서는 현재 구성이 특정 FPGA에 적합한지 여부를 결정하는 데 유용합니다.

리소스 요구 사항이 염두에 둔 FPGA에 비해 너무 높다면 'target_fps'를 낮추는 것을 고려해야 합니다.

**분석 모델은 다양한 합성 최적화의 효과를 포착할 수 없기 때문에 필요한 리소스의 양을 과대 추정하는 경향이 있다는 점에 유의하세요.**

#### 11.4. 이해하기
JSON 파일을 읽어서 딕셔너리 객체로 변환하여 파이썬에서도 쉽게 사용할 수 있게 만듭니다.

1. `estimate_layer_cycles.json` 은 이름과 해당 레이어에서의 예상 사이클 수를 나타냅니다.  

2. `estimate_layer_resources.json`은 레이어별 리소스 추정치를 알 수 있습니다.

---
## 11.5. Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance - 1 
---
**빌드를 시작합니다: 스티치된 IP, 컨텍스트 외 신디사이저 및 rtlsim 성능**

만족스러운 추정치를 제공하는 구성이 완료되면 가속기를 생성하는 단계로 넘어갈 수 있습니다.

가속기를 더 큰 시스템에 통합하려는 방식에 따라 다양한 방법으로 이 작업을 수행할 수 있습니다.

예를 들어, Vivado에 더 큰 스트리밍 시스템이 구축되어 있거나 이렇게 생성된 가속기를 다른 프로젝트에서 IP 구성 요소로 재사용하려는 경우 `STITCHED_IP` 출력 제품을 사용하는 것이 좋습니다.

또한 `OOC_SYNTH` 출력 제품을 사용하여 가속기의 합성 후 리소스 및 클럭 주파수 수치를 얻을 수 있습니다.

**라이브 FINN 튜토리얼:** 
이 다음 빌드는 여러 번의 Vivado 호출과 RTL 시뮬레이션 호출이 포함되므로 완료하는 데 약 10분이 소요됩니다.

이 작업이 실행되는 동안 **(사용자 AWS URL):6080/vnc.html**에서 실행되는 noVNC로 생성된 파일을 검토할 수 있습니다.

* 아래 `step_hls_codegen [8/16]`이 완료되면 각 레이어별 자체 폴더에서 생성된 HLS 코드를 확인할 수 있습니다: `/tmp/finn_dev_ubuntu/code_gen_ipgen_MVAU_hls_XXXXXX`입니다.
    
* 아래 `step_create_stitched_ip [11/16]`가 완료되면, 생성된 스티치 IP는 Vivado의 `/home/ubuntu/finn/notebooks/end2end_example/cybersecurity/output_ipstitch_ooc_rtlsim/stitched_ip`에서 볼 수 있습니다.

```python
import finn.builder.build_dataflow as build
import finn.builder.build_dataflow_config as build_cfg
import os
import shutil

model_file = model_dir + "/cybsec-mlp-ready.onnx"

rtlsim_output_dir = "output_ipstitch_ooc_rtlsim"

#Delete previous run results if exist
if os.path.exists(rtlsim_output_dir):
    shutil.rmtree(rtlsim_output_dir)
    print("Previous run results deleted!")

cfg_stitched_ip = build.DataflowBuildConfig(
    output_dir          = rtlsim_output_dir,
    mvau_wwidth_max     = 80,
    target_fps          = 1000000,
    synth_clk_period_ns = 10.0,
    fpga_part           = "xc7z020clg400-1",
    generate_outputs=[
        build_cfg.DataflowOutputType.STITCHED_IP,
        build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,
        build_cfg.DataflowOutputType.OOC_SYNTH,
    ]
)
```

```python
%%time
build.build_dataflow_cfg(model_file, cfg_stitched_ip)
```
```bash
Building dataflow accelerator from /home/lsh/FPGA/finn/notebooks/end2end_example/cybersecurity/cybsec-mlp-ready.onnx
Intermediate outputs will be generated in /tmp/finn_dev_lsh
Final outputs will be generated in output_ipstitch_ooc_rtlsim
Build log is at output_ipstitch_ooc_rtlsim/build_dataflow.log
Running step: step_qonnx_to_finn [1/19]
Running step: step_tidy_up [2/19]
Running step: step_streamline [3/19]
Running step: step_convert_to_hw [4/19]
Running step: step_create_dataflow_partition [5/19]
Running step: step_specialize_layers [6/19]
Running step: step_target_fps_parallelization [7/19]
Running step: step_apply_folding_config [8/19]
Running step: step_minimize_bit_width [9/19]
Running step: step_generate_estimate_reports [10/19]
Running step: step_hw_codegen [11/19]
Running step: step_hw_ipgen [12/19]
Running step: step_set_fifo_depths [13/19]
Running step: step_create_stitched_ip [14/19]
Running step: step_measure_rtlsim_performance [15/19]
Running step: step_out_of_context_synthesis [16/19]
Running step: step_synthesize_bitfile [17/19]
Running step: step_make_pynq_driver [18/19]
Running step: step_deployment_package [19/19]
Completed successfully
CPU times: user 1.96 s, sys: 1.29 s, total: 3.25 s
Wall time: 5min 14s
```
<br>

#### 11.5. 이해하기
첫 부분은 `11.1.1` 과 동일한 방식이지만 출력물이 늘었기 때문에 그만큼 러닝 타임도 늘어납니다.

`build` 된 것들을 살펴보면 다음과 같습니다.

1. QONNX에서 FINN으로 변환 (step_qonnx_to_finn)
    - QONNX 형식의 모델을 FINN 내부 표현으로 변환합니다.

2. 정리 (step_tidy_up)
    - 모델 구조를 정리하고 최적화합니다. 이 단계에는 shape 및 데이터 타입 추론, 상수 폴딩, 노드와 텐서에 더 나은 이름 부여 등이 포함됩니다.
3. 스트림라인 최적화 (step_streamline)
    - 모델 구조를 최적화하고 단순화합니다.
4. 하드웨어 변환 (step_convert_to_hw)
    - 소프트웨어 모델을 하드웨어 구현으로 변환합니다. 특정 노드들을 HW 레이어를 나타내는 HWCustomOp 서브클래스로 변환합니다.
5. 데이터플로우 파티션 생성 (step_create_dataflow_partition)
    - 모델을 여러 StreamingDataflowPartition으로 분할합니다. 이는 향후 플로어플래닝을 용이하게 하기 위함입니다.
6. 레이어 특수화 (step_specialize_layers)
    - 각 레이어에 대해 특정 구현 스타일을 설정합니다.
7. 목표 FPS 병렬화 (step_target_fps_parallelization)
    - 목표 FPS를 달성하기 위해 모델의 병렬화 수준을 조정합니다.
8. 폴딩 설정 적용 (step_apply_folding_config)
    - 폴딩 설정 파일을 모델에 적용하여 병렬화 및 기타 속성을 설정합니다.
9. 비트 폭 최소화 (step_minimize_bit_width)
    - 데이터 표현의 비트 수를 최적화합니다.
10. 추정 보고서 생성 (step_generate_estimate_reports)
    - 리소스 사용량 및 성능에 대한 추정 보고서를 생성합니다.
11. 하드웨어 코드 생성 (step_hw_codegen)
    - HLS 또는 RTL 코드를 생성합니다.
12. 하드웨어 IP 생성 (step_hw_ipgen)
    - FPGA IP 블록을 생성합니다.
13. FIFO 깊이 설정 (step_set_fifo_depths)
    - 스트리밍 노드 사이에 FIFO 노드를 삽입하고 깊이를 설정합니다.
14. 스티치된 IP 생성 (step_create_stitched_ip)
    - 생성된 IP 블록들을 연결하여 전체 시스템을 구성합니다.
15. RTL 시뮬레이션 성능 측정 (step_measure_rtlsim_performance)
    - 생성된 하드웨어의 성능을 RTL 시뮬레이션을 통해 검증합니다.
16. Out-of-Context 합성 (step_out_of_context_synthesis)
    - FPGA 리소스 사용량을 추정하기 위해 Out-of-Context 합성을 수행합니다.
17. 비트파일 합성 (step_synthesize_bitfile)
    - 최종 FPGA 비트파일을 생성합니다.
18. PYNQ 드라이버 생성 (step_make_pynq_driver)
    - PYNQ 보드용 Python 드라이버를 생성합니다.
19. 배포 패키지 생성 (step_deployment_package)
    - 최종 구현을 위한 배포 패키지를 생성합니다.


---
## 11.6. Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance -2 
---
```python
assert os.path.exists(rtlsim_output_dir + "/report/ooc_synth_and_timing.json")
assert os.path.exists(rtlsim_output_dir + "/report/rtlsim_performance.json")
assert os.path.exists(rtlsim_output_dir + "/final_hw_config.json")

```
<br>

출력 제품에 비트파일을 요청하지 않았는데도 위에 `step_synthesize_bitfile`이 나열된 이유는 무엇인가요? 

이는 기본 빌드 단계 집합에 `step_synthesize_bitfile`이 포함되어 있기 때문입니다.

출력 제품이 선택되지 않았으므로 이 단계에서는 아무 작업도 수행하지 않습니다.

결과물 중 스티치된 IP 블록 디자인으로 내보낸 가속기를 확인할 수 있습니다:

```python
! ls {rtlsim_output_dir}/stitched_ip
```
```bash
all_verilog_srcs.txt		       finn_vivado_stitch_proj.xpr
data				       ip
finn_vivado_stitch_proj.cache	       make_project.sh
finn_vivado_stitch_proj.gen	       make_project.tcl
finn_vivado_stitch_proj.hw	       vivado.jou
finn_vivado_stitch_proj.ip_user_files  vivado.log
finn_vivado_stitch_proj.srcs
```
<br>

#### 11.6. 이해하기
위에서 생성된 파일들은 다음과 같습니다.
1. Vivado 프로젝트 파일
    - finn_vivado_stitch_proj.xpr: Vivado 프로젝트의 메인 파일로, 이 파일을 통해 프로젝트를 열 수 있습니다.
2. 소스 및 생성 파일
    - all_verilog_srcs.txt: 프로젝트에서 사용된 모든 Verilog 소스 파일의 목록입니다.

    - finn_vivado_stitch_proj.srcs: Vivado 프로젝트의 소스 파일들이 포함된 디렉토리입니다.

    - finn_vivado_stitch_proj.gen: Vivado 프로젝트에서 생성된 파일들이 저장된 디렉토리입니다.

3. IP 관련 파일
      - ip: 생성된 IP(Intellectual Property) 블록들이 저장된 디렉토리입니다.
    
      - finn_vivado_stitch_proj.ip_user_files: 사용자 정의 IP 파일들이 저장된 디렉토리입니다.

4. 하드웨어 관련 파일
    - finn_vivado_stitch_proj.hw: Vivado 프로젝트의 하드웨어 관련 파일들이 포함된 디렉토리입니다.

5. 프로젝트 생성 및 빌드 스크립트
    - make_project.sh: Vivado 프로젝트를 생성하기 위한 셸 스크립트 파일입니다.

    - make_project.tcl: Vivado 프로젝트를 생성하기 위한 TCL 스크립트 파일입니다.

6. 로그 및 캐시 파일
    - vivado.jou: Vivado 실행 중의 작업 기록이 담긴 로그 파일입니다.

    - vivado.log: Vivado 실행 로그 파일로, 디버깅 및 분석에 사용됩니다.

    - finn_vivado_stitch_proj.cache: Vivado 프로젝트의 캐시 파일로, 빌드 프로세스 중 생성된 임시 데이터가 저장됩니다.
7. 기타
    - data: 프로젝트와 관련된 데이터 파일들이 저장된 디렉토리입니다.


---
## 11.7.  Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance - 3
---
또한 이러한 출력 제품에서 생성되는 몇 가지 보고서가 있는데, `ESTIMATE_REPORTS`에서 생성되는 보고서와는 다릅니다.

```python
! ls {rtlsim_output_dir}/report
```
```bash
#출력
estimate_layer_resources_hls.json  rtlsim_performance.json
ooc_synth_and_timing.json
```
<br>

ooc_synth_and_timing.json`에서 가속기에 대한 사후 합성 및 최대 클럭 주파수 추정치를 찾을 수 있습니다.

여기서 클럭 주파수 추정치는 컨텍스트 외 합성이 제약이 적기 때문에 낙관적인 경향이 있습니다.

```python
! cat {rtlsim_output_dir}/report/ooc_synth_and_timing.json
```
```bash
{
  "vivado_proj_folder": "/tmp/finn_dev_lsh/synth_out_of_context_erfpv9v4/results_finn_design_wrapper",
  "LUT": 6261.0,
  "LUTRAM": 42.0,
  "FF": 8964.0,
  "DSP": 0.0,
  "BRAM": 22.0,
  "BRAM_18K": 0.0,
  "BRAM_36K": 22.0,
  "URAM": 0.0,
  "Carry": 290.0,
  "WNS": 0.457,
  "Delay": 0.457,
  "vivado_version": 2023.2,
  "vivado_build_no": 4029153.0,
  "": 0,
  "fmax_mhz": 104.7888504663104,
  "estimated_throughput_fps": 1637325.7885361
}
```
<br>

rtlsim_performance.json`에서 가속기의 정상 상태 처리량과 지연 시간을 확인할 수 있습니다. 

여기에 보고된 DRAM 대역폭 수치가 하드웨어 플랫폼의 성능보다 낮으면(즉, 가속기가 메모리에 구속되지 않는 경우) 실제 하드웨어에서 동일한 정상 상태 처리량(소프트웨어/드라이버 오버헤드 제외)을 기대할 수 있습니다.

```python
! cat {rtlsim_output_dir}/report/rtlsim_performance.json
```
```bash
{
  "N_IN_TXNS": 15,
  "N_OUT_TXNS": 1,
  "cycles": 224,
  "N": 1,
  "latency_cycles": 224,
  "runtime[ms]": 0.0022400000000000002,
  "throughput[images/s]": 446428.5714285714,
  "fclk[mhz]": 100.0,
  "stable_throughput[images/s]": 446428.5714285714
}
```
<br>

#### 11.7. 이해하기
출력물에서 다음과 같은 3가지 `.json` 파일이 생성되었으며 다음과 같습니다.
1. `estimate_layer_resources_hls.json :` 
    - 이 파일은 각 레이어의 HLS(High-Level Synthesis) 리소스 추정치를 포함합니다.

    - 각 레이어별로 FPGA에서 사용될 것으로 예상되는 리소스(LUT, FF, BRAM, DSP 등)의 양을 제공합니다.

2. `rtlsim_performance.json :`
    - RTL 시뮬레이션을 통해 측정된 성능 데이터를 포함합니다.
    
    - 전체 네트워크와 개별 레이어의 처리 시간, 처리량 등의 성능 지표를 제공합니다.

    - 여기서 분석을 하였을 때 다음의 정보를 얻을 수 있습니다.
      - 입력 및 출력 트랜잭션의 수 : 이는 가속기가 처리하는 데이터의 개수를 의미합니다
      
      - 사이클 수

      - 처리된 입력 샘플

      - 지연 시간 클럭 사이클

      - 동작 시간 등등..

3. `ooc_synth_and_timing.json :`
    - Out-of-Context(OOC) 합성 및 타이밍 분석 결과를 포함합니다.

    - 실제 FPGA 타겟에 대한 합성 결과와 타이밍 정보를 제공합니다.
    
    - 리소스 사용량, 클록 주파수, 타이밍 제약 충족 여부 등의 중요한 정보를 포함합니다.

    - 여기서 분석을 하였을 때 다음의 정보를 얻을 수 있습니다.
      - 리소스 사용량
        - LUT, LUTRAM, FF, DSP, BRAM, URAM 
      - 타이밍 정보
        - WNS , fmax_Mhz
      - 성능 추정 
        - 예상 처리량 

---
## 11.8. Launch a Build: Stitched IP, out-of-context synth and rtlsim Performance - 4
---
마지막으로 `final_hw_config.json`을 살펴봅시다.

이것은 FIFO 깊이, 병렬화 설정(PE/SIMD) 등을 포함하여 FINN 컴파일러에 의해 결정되는 노드별 하드웨어 구성입니다.

빌드를 더 최적화하려면('성능 구성하기'에서 언급한 '고급' 방법) 이 .json 파일을 새 실행의 `folding_config_file`로 사용하여 추가 탐색 및 최적화를 위한 시작점으로 사용할 수 있습니다.

```python
! cat {rtlsim_output_dir}/final_hw_config.json
```
```bash
{
  "Defaults": {},
  "StreamingFIFO_rtl_0": {
    "ram_style": "auto",
    "depth": 32,
    "impl_style": "rtl",
    "inFIFODepths": [
      0
    ],
    "outFIFODepths": [
      0
    ]
  },
  "MVAU_hls_0": {
    "PE": 16,
    "SIMD": 40,
    "ram_style": "auto",
    "resType": "auto",
    "mem_mode": "internal_decoupled",
    "runtime_writeable_weights": 0,
    "inFIFODepths": [
      32
    ],
    "outFIFODepths": [
      2
    ]
  },
  "StreamingFIFO_rtl_1": {
    "ram_style": "auto",
    "depth": 2,
    "impl_style": "rtl",
    "inFIFODepths": [
      0
    ],
    "outFIFODepths": [
      0
    ]
  },
  "StreamingDataWidthConverter_rtl_0": {
    "inFIFODepths": [
      2
    ],
    "outFIFODepths": [
      2
    ]
  },
  "StreamingFIFO_rtl_2": {
    "ram_style": "auto",
    "depth": 2,
    "impl_style": "rtl",
    "inFIFODepths": [
      0
    ],
    "outFIFODepths": [
      0
    ]
  },
  "MVAU_hls_1": {
    "PE": 1,
    "SIMD": 64,
    "ram_style": "auto",
    "resType": "auto",
    "mem_mode": "internal_decoupled",
    "runtime_writeable_weights": 0,
    "inFIFODepths": [
      2
    ],
    "outFIFODepths": [
      2
    ]
  },
  "StreamingFIFO_rtl_3": {
    "ram_style": "auto",
    "depth": 2,
    "impl_style": "rtl",
    "inFIFODepths": [
      0
    ],
    "outFIFODepths": [
      0
    ]
  },
  "StreamingDataWidthConverter_rtl_1": {
    "inFIFODepths": [
      2
    ],
    "outFIFODepths": [
      2
    ]
  },
  "StreamingFIFO_rtl_4": {
    "ram_style": "auto",
    "depth": 2,
    "impl_style": "rtl",
    "inFIFODepths": [
      0
    ],
    "outFIFODepths": [
      0
    ]
  },
  "MVAU_hls_2": {
    "PE": 1,
    "SIMD": 64,
    "ram_style": "auto",
    "resType": "auto",
    "mem_mode": "internal_decoupled",
    "runtime_writeable_weights": 0,
    "inFIFODepths": [
      2
    ],
    "outFIFODepths": [
      2
    ]
  },
  "StreamingFIFO_rtl_5": {
    "ram_style": "auto",
    "depth": 2,
    "impl_style": "rtl",
    "inFIFODepths": [
      0
    ],
    "outFIFODepths": [
      0
    ]
  },
  "MVAU_hls_3": {
    "PE": 1,
    "SIMD": 1,
    "ram_style": "auto",
    "resType": "auto",
    "mem_mode": "internal_decoupled",
    "runtime_writeable_weights": 0,
    "inFIFODepths": [
      2
    ],
    "outFIFODepths": [
      2
    ]
  },
  "StreamingFIFO_rtl_6": {
    "ram_style": "auto",
    "depth": 2,
    "impl_style": "rtl",
    "inFIFODepths": [
      0
    ],
    "outFIFODepths": [
      0
    ]
  }
}
```
<br>
---

#### 11.8. 이해하기
`final_hw_config.json`는 하드웨어 구성을 보여줍니다.
1. StreamingFIFO 컴포넌트
    - 여러 StreamingFIFO 컴포넌트(0부터 6까지)가 있으며, 주로 다음과 같은 설정을 가집니다:
    - ram_style: "auto"
    - depth: 대부분 2, 첫 번째는 32
    - impl_style: "rtl"
      - 이 FIFO들은 레이어 간 데이터 버퍼링을 위해 사용됩니다.

2. MVAU (Matrix-Vector Activation Unit) 컴포넌트
    - 4개의 MVAU 컴포넌트가 있으며, 각각 다른 설정을 가집니다:
    - MVAU_hls_0:
      - PE: 16, SIMD: 40
      - 입력 FIFO 깊이: 32, 출력 FIFO 깊이: 2
    - MVAU_hls_1 및 MVAU_hls_2:
      - PE: 1, SIMD: 64
      - 입력/출력 FIFO 깊이: 2
    - MVAU_hls_3:
      - PE: 1, SIMD: 1
      - 입력/출력 FIFO 깊이: 2
        - 모든 MVAU는 mem_mode가 "internal_decoupled"로 설정되어 있어, 내부 메모리를 사용하며 입출력이 분리되어 있음을 나타냅니다.

3. StreamingDataWidthConverter 컴포넌트
    - 두 개의 StreamingDataWidthConverter가 있으며, 데이터 폭을 변환하는 역할을 합니다.

4. 최적화 가능성
  - 이 구성을 기반으로 다음과 같은 최적화를 고려할 수 있습니다:
    - MVAU_hls_0의 PE와 SIMD 값 조정
    - FIFO 깊이 최적화
    - 메모리 스타일 ('ram_style') 조정
    - PE와 SIMD 값의 전반적인 균형 조정 





---
## 11.9. (Optional) Launch a Build: PYNQ Bitfile and Driver 
**(선택 사항) 빌드를 시작합니다: PYNQ 비트파일 및 드라이버**

**라이브 FINN 튜토리얼:** 이 섹션은 비트파일 합성 시간(15~20분)으로 인해 실습 튜토리얼에 포함되지 않습니다.

PYNQ 보드를 소유하고 있는 경우 튜토리얼이 끝난 후 아래 셀의 주석을 해제하여 직접 사용해 보시기 바랍니다.

## 11.10. (Optional) Run on PYNQ board
**## **(선택 사항) PYNQ 보드에서 실행**

**라이브 FINN 튜토리얼:** 이 섹션은 이전 섹션의 비트파일 합성 시간(15~20분)으로 인해 실습 튜토리얼에 포함되지 않습니다.
 
PYNQ 보드를 소유하고 있는 경우 튜토리얼이 끝난 후 아래 셀의 주석을 해제하여 직접 사용해 보시기 바랍니다.

**저는 PYNQ 보드가 없기 때문에 이 과정은 생략하였습니다.**





---