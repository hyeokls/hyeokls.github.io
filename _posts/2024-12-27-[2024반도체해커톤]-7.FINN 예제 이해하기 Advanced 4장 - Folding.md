---
title: "[2024반도체해커톤] 7.FINN 예제 이해하기 Advanced 4장 - Folding"
date: 2024-12-27 11:24:00 +09:00
categories: [Project, 2024_2 반도체해커톤,]
tags:
  [
    verilog,
    systemverilog,
    Vivado,
    Vitis,
    Xilinx,
    FINN,
    Bretivas
  ]
---

## 환경사항
사용하고 있는 환경은 다음과 같다.

| 이름                      | 버전       | 기타 정보 |
| :-------------------------------| :-----------------| :-------: |
| Vivado			| 2023.2		| O	|
| Vitis			| 2023.2		| O	|
| WSL2			| 5.15.167.4	| O	|
| Ubuntu			| 20.04.06	| O	|
| Docker Desktop		|		| O	|


## 목차 
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-0.WLS2-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%ED%95%98%EB%93%9C%EC%9B%A8%EC%96%B4-%EC%9E%A5%EB%B9%84-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0/">0. WSL2 환경에서 하드웨어 장비 연결하기<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-1.%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0/">1. 환경 설정하기<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-2.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-1%ED%8E%B8-How-to-work-with-onnx/">2. FINN 예제 이해하기 1편 Basics - How to used finn<br>
<a href="https://hyeokls.github.io/posts/2024GC%ED%95%B4%EC%BB%A4%ED%86%A4-3.FINN-%EC%98%88%EC%A0%9C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-2%ED%8E%B8-Brevitas-netowrk-import-via-QONNX/">3. FINN 예제 이해하기 2편 - Brevitas network import via QONNX<br>


# 이번 챕터에서는 무엇을 했나요?
저번 챕터와 마찬가지로 며칠동안은 FINN에서 제공하는 예제를 이해하는 시간을 가졌습니다.

이번 챕터는 FINN의 변환 패스에 대한 개념을 설명하고 예제를 통해 변환의 절차를 공부할 예정입니다.

---
## 7.0.1. FINN - Folding
---
**참고: cybersecurity end2end example**의 과정에서 생성된 중간 모델 중 하나를 활용합니다. 

이는 추후에 글을 작성할 예정입니다.

이 디렉터리에는 `step_specialize_layers.onnx`의 로컬 복사본이 있으며, 이 복사본은 `cybsec_PE_SIMD.onnx`로 이름이 변경되어 이 튜토리얼을 진행하기 위한 필수 요소 없이도 사용할 수 있습니다. 

그러나 [세 번째 사이버 보안 주피터 노트북]을 사용하여 직접 생성할 수도 있습니다. 

추정 전용 빌드 흐름 실행 후 '../end2end_example/cybersecurity/출력_추정 전용/중간 모델/스텝_특화 레이어.onnx'에서 찾을 수 있습니다. 

이 노트북에서는 폴딩 인자라고도 하는 FINN 병렬화 매개변수(PE 및 SIMD)를 사용하여 모델을 효율적으로 최적화하여 최대 성능을 추출하는 방법에 대해 설명합니다. 

폴딩 인자는 임의로 선택할 수 없으며, 각 레이어마다 병렬화 파라미터를 설정할 수 있는 값에 대한 제약이 있으므로 자세한 내용은 [여기](https://finn-dev.readthedocs.io/en/latest/internals.html#constraints-to-folding-factors-per-layer)를 참조하세요.
 
유틸리티 함수 `showInNetron()`을 사용하여 Jupyter 노트북에서 네트워크를 시각화하고 상호 작용하고, `showSrc()`를 사용하여 FINN 라이브러리 호출의 소스 코드를 표시하겠습니다.

---
## 7.1. Netron Src 설정하기.
---
```python
from finn.util.visualization import showInNetron, showSrc
```

참고: cybsec_mlp 노트북의 build_flow는 `SetFolding` [변환](https://github.com/Xilinx/finn/blob/main/src/finn/transformation/fpgadataflow/set_folding.py#L46)을 호출하여 
주어진 `target_fps`를 달성하는 데 필요한 사용자 지정 병렬화 파라미터를 자동으로 설정하는 변환 단계 `step_target_fps_parallelization`으로 구성되어 있습니다.

위 단계에 대한 자세한 내용은 [여기](https://github.com/Xilinx/finn/blob/main/src/finn/builder/build_dataflow_steps.py#L394)에서 확인할 수 있습니다.

이 노트북은 이 단계의 수동 버전을 보여주며, 네트워크 성능을 극대화해야 하는 개발자를 위해 이러한 속성이 어떻게 성능을 개선할 수 있는지, 리소스 활용에 어떤 영향을 미치는지 설명합니다. 

이를 위해 `cybsec_PE_SIMD.onnx` 파일을 시작점으로 사용합니다. 사이버 보안 예시의 이 중간 모델은 상위 수준의 ONNX 레이어가 HW 레이어로 변환된 후 HLS 또는 RTL 변형으로 특수화된 후의 모델 표현입니다. 

이 예제에서는 모든 노드가 HLS 변형으로 변환되었으므로 그래프의 각 노드는 이제 HLS C++ 함수 호출에 해당하며 노드 속성을 사용하여 병렬화 매개변수를 설정할 수 있습니다.

이 모델을 사용하여 폴딩 인자를 수동으로 설정하고 네트워크의 각 계층의 예상 실행 클록 주기와 리소스 사용률을 분석하는 방법을 보여드리겠습니다.

---
## 7.2. FINN-style Dataflow Architectures
---
먼저 FINN 스타일의 데이터 흐름 아키텍처에 대해 간략히 살펴보겠습니다.

이러한 아키텍처의 핵심 아이디어는 아래 그림과 같이 각 레이어에 비례적인 양의 컴퓨팅 리소스를 할당하여 레이어 간은 물론 레이어 내에서도 병렬화하는 것입니다.

![](핀-데이터흐름.png)

실제로 레이어는 [finn-hlslib](https://github.com/Xilinx/finn-hlslib) 라이브러리에서 최적화된 Vitis HLS 빌딩 블록에 대한 함수 호출 또는 [finn-rtllib](https://github.com/Xilinx/finn/tree/main/finn-rtllib)의 RTL 모듈에 의해 인스턴스화됩니다.

각 레이어가 인스턴스화되므로 아래 이미지와 같이 각 레이어의 병렬화를 유연하게 설정하여 네트워크의 리소스와 처리량을 제어할 수 있습니다:

![](finn-folding.png)


---
## 7.3. Part-1 : Lodaing the ONNX model.
---
1부: ONNX 모델 로드하기.

위에서 설명한 것처럼 네트워크는 추정 함수에 입력하기 전에 몇 가지 준비 단계를 거쳐야 합니다.

여기에 로드된 '.onnx' 파일은 사이버 보안 엔드투엔드 예제 노트북에서 가져온 것입니다. 

이 노트북에 필요한 변환이 적용된 onnx 파일 `cybsec_PE_SIMD.onnx`를 선택합니다. 

즉, 네트워크 레이어가 필요한 FINN-HW 블록에 매핑됩니다. 

이 경우, MatrixVectorActivation의 HLS 변형인 `MVAU_hls` 단위입니다. 

.onnx` 파일과 상호 작용하려면 `ModelWrapper()`를 사용합니다. 

이 래퍼는 다양한 모델 속성에 대한 액세스를 단순화하고 모델에 사용자 정의 변환을 적용할 수 있게 해줍니다.

아래 셀에서는 onnx 파일을 로드하고 Netron에서 cybersecurity MLP 네트워크를 확인합니다. 

또한, 준비 작업으로 `GiveUniqueNodeNames` 변환을 호출합니다.

```python
import os
from qonnx.core.modelwrapper import ModelWrapper
from qonnx.transformation.general import GiveUniqueNodeNames

model = ModelWrapper(os.environ["FINN_ROOT"] + "/notebooks/advanced/cybsec_PE_SIMD.onnx")
model = model.transform(GiveUniqueNodeNames())
model_path = os.environ["FINN_ROOT"] + "/notebooks/advanced/cybsec_PE_SIMD_named_nodes.onnx"
model.save(model_path)

showInNetron(model_path)
```
<br>

#### 7.3. 이해하기
위 코드는 특정 위치에 있는 `.onnx` 파일을 래핑한 뒤 새로운 위치에 저장하는 코드입니다.
1. `GiveUniqueNodeNames` 을 사용하여 모델의 각 노드에 고유한 이름을 할당할 수 있게 합니다.

2. 모델을 로드한 뒤 고유한 이름을 할당합니다.

3. 특정 경로를 지정한 뒤 모델을 저장합니다. 

4. Netron 으로 보여줍니다

- PE_SIMD 에 관한 ONNX 이미지 출력

---
## 7.4. Part 2 : Parallelization Parameters: PE & SIMD -1 
---
계산 병렬화는 각 레이어의 폴딩 인자 또는 병렬화 매개변수 **PE** 및 **SIMD**를 설정하여 변경할 수 있습니다.

이러한 병렬화 속성은 특정 제약 조건이 적용되므로 그에 따라 선택해야 합니다.

MatrixVectorActivation 계층의 HLS 변형(`MVAU_hls`)에서 이것이 어떻게 구현되는지 자세히 알아보려면 [이 문서](https://github.com/Xilinx/finn/blob/github-pages/docs/finn-sheduling-and-folding.pptx)를 참조하세요.

완전히 연결된 레이어에 대한 MVAU의 폴딩 모식도는 아래와 같습니다:

![](핀 폴딩 엠바우.png)

MVAU의 경우 `PE` 및 `SIMD`에는 다음과 같은 제약 조건이 적용됩니다: 

MW`는 입력 특징의 수이고 `MH`는 출력 특징의 수입니다:

        MW % SIMD == 0
        MH % PE == 0
        
MVAU의 경우 총 폴딩은 다음과 같이 정의됩니다:

    총 폴딩 = (MH/PE) x (MW/SIMD)

FINN 설계와 같은 스트리밍 데이터 흐름 아키텍처에서 처리량은 가장 느린 레이어에 의해 결정됩니다.

따라서 이러한 매개변수를 조정하는 목표는 거의 균형 잡힌 파이프라인, 즉 생성된 데이터 흐름 아키텍처에서 레이어의 처리량 속도를 균등화하는 것입니다.

FINN 컴파일러는 각 레이어의 폴딩 인자를 쉽게 탐색할 수 있는 분석 패스를 제공합니다. 

이 노트북에서는 이러한 함수를 사용하는 방법을 보여주고 병렬화 매개변수가 생성된 데이터 흐름 아키텍처의 클록 주기와 리소스 활용에 어떤 영향을 미치는지 살펴보겠습니다.

모든 레이어에서 `PE` 및 `SIMD` 값이 1인 경우로 시작하며, 이는 탐색의 시작점이자 HLS 레이어로 변환한 후 네트워크의 상태이기도 합니다. 

Netron을 사용하여 모델을 살펴보고 MVAU 레이어 중 하나를 클릭하면 `PE`와 `SIMD`가 모두 기본적으로 1로 설정되어 있는 것을 확인할 수 있습니다.

```python
showInNetron(model_path)
```

#### 7.4 이해하기

MatrixVectorActivation (MVAU)의 병렬성
병렬성(Parallelism)이란?
- 병렬성은 여러 연산을 동시에 수행하여 계산 효율을 크게 높이는 방법입니다.

- MVAU_hls(MatrixVectorActivation의 HLS 변형)에서는 병렬화 파라미터, 즉 PE와 SIMD를 설정하여 병렬성을 제어합니다.

PE와 SIMD란?

- PE (Processing Elements): 레이어의 뉴런 중 몇 개가 동시에 입력을 처리할 수 있는지를 결정합니다.

- SIMD (Single Instruction, Multiple Data): 각 뉴런이 동시에 처리할 수 있는 입력 데이터의 개수를 제어합니다.

PE와 SIMD의 제약 조건

- 이 파라미터들은 FPGA의 논리 자원과 메모리 같은 하드웨어 자원의 한계에 영향을 받습니다.

- PE와 SIMD 값을 선택할 때는 병렬성과 자원 사용량 간의 균형을 맞춰야 합니다.

Folding(폴딩) 구현 방법

- **폴딩(Folding)**은 계산을 더 작은 작업 단위로 나누어 자원 제약을 해결하는 방법입니다.

- 예를 들어, 완전한 병렬 처리가 불가능한 경우 폴딩을 통해 순차적으로 연산을 수행하면서도 동일한 결과를 얻을 수 있습니다.

MVAU 폴딩 구조도

- finn-folding-mvau.png 이미지에 표시된 구조도는 완전 연결 레이어가 입력과 가중치를 PE와 SIMD 설정에 따라 처리하는 방식을 보여줍니다.

- 입력 데이터는 그룹화되어 여러 PE에서 동시에 처리되고, 가중치는 순차적으로 또는 병렬로 접근하여 연산됩니다.

관련 문서 참고

- MVAU_hls에서 사용하는 스케줄링 및 폴딩 메커니즘에 대한 자세한 내용은 문서 링크를 참조하세요.

핵심 요약
- PE와 SIMD를 구성함으로써 뉴럴 네트워크 레이어의 병렬성 정도를 조정할 수 있으며, 이는 속도와 자원 사용량 간의 균형을 맞추는 데 중요합니다. 폴딩은 제한된 하드웨어 자원 내에서 효율적으로 연산을 수행할 수 있도록 돕는 기술입니다.



---
## 7.5. Part 2 : Parallelization Parameters: PE & SIMD -2
---
각 네트워크 계층의 클록 주기 수와 리소스 사용률을 추정하기 위해 분석 패스 `exp_cycles_per_layer()`와 `res_estimation()`을 가져옵니다.

```python
from functools import partial
from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer
from finn.analysis.fpgadataflow.res_estimation import res_estimation
```
<br>

FINN의 분석 패스는 모델에 대한 정보를 사전 형태로 반환하며, 분석 패스에 대한 일반적인 내용은 이 Jupyter 노트북에서 자세히 알아볼 수 있습니다: [0_custom_analysis_pass.ipynb](0_custom_analysis_pass.ipynb).

먼저 분석 패스인 `exp_cycles_per_layer()`를 호출하여 레이어 이름을 키로, 예상 주기를 값으로 하는 사전을 반환합니다. 

그런 다음 결과를 블록 다이어그램에 플롯합니다.

```python
cycles_dict = model.analysis(exp_cycles_per_layer)
cycles_dict
```
```bash
#출력
{'MVAU_hls_0': 38400, 'MVAU_hls_1': 4096, 'MVAU_hls_2': 4096, 'MVAU_hls_3': 64}
```
<br>

```python
import matplotlib.pyplot as plt

fig = plt.figure(figsize = (10, 5))
plt.bar(cycles_dict.keys(), cycles_dict.values(), color ='blue', width = 0.3)
plt.xlabel("Network layers")
plt.ylabel("Number of clock cycles")
plt.title("Clock cycles per layer PE=SIMD=1")
plt.show()
```
<br>

- 이미지 첨부

하드웨어에서 모델을 실행할 때 병목 현상은 한 세트의 입력을 실행하는 데 약 38400 클럭 사이클이 걸리는 첫 번째 계층의 실행에서 발생하는 것으로 관찰되었습니다.

다른 레이어가 아무리 빨리 실행되더라도 처리량은 첫 번째 레이어의 실행 지연 시간에 의해 정의됩니다.

#### 7.5. 이해하기


---
## 7.6. Part 2 : Parallelization Parameters: PE & SIMD - 3 
---

이제 다른 분석 패스를 호출하여 레이어당 예상 리소스를 살펴보겠습니다.

키는 다시 레이어 이름이지만 값은 이제 레이어별 리소스 추정치가 포함된 딕셔너리입니다.

```python
res_dict = model.analysis(partial(res_estimation, fpgapart="xc7z020clg400-1"))
res_dict
```
```bash
#출력
{'MVAU_hls_0': {'BRAM_18K': 5,
  'BRAM_efficiency': 0.8333333333333334,
  'LUT': 319,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_1': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.4444444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_2': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.4444444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_3': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.006944444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0}}
```
<br>

분석 패스는 LUT, BRAM, URAM 및 DSP의 절대 수와 함께 메모리 사용 효율에 대한 정보도 제공합니다. 

메모리 유형을 사용하지 않는 경우 효율성은 기본적으로 1입니다. 위의 `URAM_efficiency`에서 이를 확인할 수 있습니다.

다른 모든 경우의 효율은 필요한 실제 매개변수 저장 공간을 할당된 BRAM/URAM 저장 공간으로 나눈 값입니다.

따라서 이 예제에서 MVAU_hls_0은 5개의 블록 램을 사용하며 83%의 사용률을 나타냅니다. 

#### 7.6. 이해하기


---
## 7.7. Part 2 : Parallelization Parameters: PE & SIMD -4 
---

모델에서 해당 정보를 추출한 후 LUT의 수를 플롯합니다. 

이 노트북에서는 LUT 사용량에 미치는 영향에 초점을 맞추었지만 아래 코드를 조작하여 메모리 및 dsp 사용량에 대한 정보도 추출할 수 있습니다.

```python
# Extracting LUTs from res_dict
LUTs = [res_dict[key]["LUT"] for key in res_dict.keys()]   

#Plotting the bar graph of each network layer with their corresponding LUT resource utilization
fig = plt.figure(figsize = (10, 5))
plt.bar(res_dict.keys(), LUTs, color ='green', width = 0.3)
plt.xlabel("Network layers")
plt.ylabel("Number of LUTs")
plt.title("No. of LUTs per layer PE=SIMD=1")
plt.show()
```
<br>

-이미지 첨부

위에서 첫 번째 레이어가 실행을 완료하는 데 가장 많은 사이클이 걸린다는 것을 확인했으므로 이제 폴딩 매개 변수를 조정하여 리소스 사용률을 높이는 대신 지연 시간을 줄여 보겠습니다.

---
## 7.8. Modify Parameters -1
---

**매개변수 수정**

이제 첫 번째 네트워크 계층의 병렬화 매개변수를 수정하여 지연 시간을 줄입니다.

모델에서 첫 번째 `MVAU_hls` 블록만 추출하고 병렬화 파라미터를 수동으로 설정합니다.

첫 번째 단계에서는 모든 레이어의 `PE` 및 `SIMD` 값을 기본값(=1)으로 두고 기준선을 설정하고 각 개별 레이어의 예상 클록 주기 및 리소스 사용률을 측정했습니다.

PE` 및 `SIMD`를 설정하기 위해 FINN 컴파일러의 기능을 활용합니다. 각 레이어 유형에는 `getCustomOp()` 함수를 사용하여 인스턴스화할 수 있는 Python 래퍼가 있습니다. 

이 래퍼는 노드의 어트리뷰트에 액세스하고 설정하기 위해 `get_nodeattr()` 및 `set_nodeattr()`과 같은 여러 도우미 함수를 제공합니다.

```python
from qonnx.custom_op.registry import getCustomOp

list_of_mvaus = model.get_nodes_by_op_type("MVAU_hls")
mvau0 = list_of_mvaus[0]

mvau0_inst = getCustomOp(mvau0)

# Get the node attributes to check the current setting
print("The parallelization parameters of %s were: " % mvau0.name)
print("PE: " + str(mvau0_inst.get_nodeattr("PE")))
print("SIMD: " + str(mvau0_inst.get_nodeattr("SIMD")))

# Set the new node attributes
mvau0_inst.set_nodeattr("PE", 2)
mvau0_inst.set_nodeattr("SIMD", 5)

# Get the node attributes to check the updated setting
print("The parallelization parameters of %s are updated to: " % mvau0.name)
print("PE: " + str(mvau0_inst.get_nodeattr("PE")))
print("SIMD: " + str(mvau0_inst.get_nodeattr("SIMD")))
```
```bash
#출력
The parallelization parameters of MVAU_hls_0 were: 
PE: 2
SIMD: 5
The parallelization parameters of MVAU_hls_0 are updated to: 
PE: 2
SIMD: 5
```
<br>

모델을 저장하고 확인합니다. 

첫 번째 `MVAU_hls`를 확장하면 해당 레이어에 대한 업데이트된 `PE` 및 `SIMD` 매개 변수를 볼 수 있습니다.

```python
model.save("cybsec_PE_SIMD_modified.onnx")
showInNetron("cybsec_PE_SIMD_modified.onnx")
```
<br>

-onnx 첨부

위의 총 폴딩 공식에서 레이어의 총 폴딩을 '600 x 64'에서 '120 x 32'로 줄였습니다. 

따라서 레이어의 실행 지연 시간이 약 '10배' 감소한 것으로 추정됩니다. 

이는 새로운 예상 클럭 주기에서 확인할 수 있습니다.

---
## 7.9. Modify Parameters - 2
---
```python
cycles_dict_updated = model.analysis(exp_cycles_per_layer)
cycles_dict_updated
```
```bash
#출력
{'MVAU_hls_0': 3840, 'MVAU_hls_1': 4096, 'MVAU_hls_2': 4096, 'MVAU_hls_3': 64}
```
<br>

```python
fig = plt.figure(figsize = (10, 5))
plt.bar(cycles_dict_updated.keys(), cycles_dict_updated.values(), color ='blue', width = 0.3)
plt.xlabel("Network layers")
plt.ylabel("Number of clock cycles")
plt.title("Clock cycles per layer with updated folding factors")
plt.show()
```
<br>

-이미지 첨부

물론 이는 네트워크의 리소스 사용량에도 영향을 미칩니다.

```python
res_dict_updated = model.analysis(partial(res_estimation, fpgapart="xc7z020clg400-1"))
res_dict_updated
```
```bash
#출력
{'MVAU_hls_0': {'BRAM_18K': 8,
  'BRAM_efficiency': 0.5208333333333334,
  'LUT': 418,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_1': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.4444444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_2': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.4444444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_3': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.006944444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0}}
```
<br>

```python
# Extracting LUTs from res_dict
LUTs_updated = [res_dict_updated[key]["LUT"] for key in res_dict_updated.keys()]   

#Plotting the bar graph of each network layer with their corresponding LUT resource utilization
fig = plt.figure(figsize = (10, 5))
plt.bar(res_dict_updated.keys(), LUTs_updated, color ='green', width = 0.3)
plt.xlabel("Network Layers")
plt.ylabel("LUT Utilisation")
plt.title("No. of LUTs per layer with updated folding factors")
plt.show()
```
<br>

- 이미지 첨부

이 수치를 통해 병목 현상이 발생하던 첫 번째 계층이 제거되어 이제 전체 네트워크가 최대 38400회의 실행 주기가 소요되던 이전 구성에 비해 최대 4096클럭 주기(파이프라인이 가득 찬 경우)에 하나의 추론을 수행할 수 있음을 알 수 있습니다.

하지만 네트워크의 실행 지연 시간이 줄어든 대신 네트워크의 첫 번째 계층에서 LUT 리소스 사용률이 45% 증가하는 비용이 발생했습니다.

---
## 7.10. Important Note : StreamingDataWidthConverters - 1 
---
**중요 참고: StreamingDataWidthConverters**

리소스와 성능 외에도 폴딩 인자(또는 병렬화 매개변수)는 생성된 디자인의 다른 속성에도 영향을 미칩니다.

결과를 병렬로 생성할 수 있으므로 레이어에 공급되는 데이터는 내부 병렬 처리를 위해 정확한 시간에 정확한 데이터를 제공하기 위해 특정 형식으로 패킹되어야 합니다.

또한 레이어에서 나오는 데이터는 내부 병렬 처리에 따라 특정 형식이 됩니다.

레이어 간 데이터 스트림에 대한 폴딩 인자의 영향을 분석하기 위해 먼저 원본 모델(`PE=SIMD=1`)을 가져온 다음 업데이트된 모델을 가져와서 두 모델을 비교할 수 있도록 합니다.

```python
dir_path = os.environ["FINN_ROOT"] + "/notebooks/advanced/" 
model_orig = ModelWrapper(dir_path + "cybsec_PE_SIMD_named_nodes.onnx")
model_updated = ModelWrapper("cybsec_PE_SIMD_modified.onnx")
```
<br>

다음 단계에서는 모든 레이어에서 정보를 추출합니다. 

MVAU의 경우 입력 모양은 (1, MW/SIMD, SIMD)이고 출력 모양은 (1, MH/PE, PE)입니다.

```python
# Original model
list_of_mvaus = model_orig.get_nodes_by_op_type("MVAU_hls")
print("In the original model (pe=simd=1): ")
for mvau in list_of_mvaus:
    mvau_inst = getCustomOp(mvau)
    print("Layer: " + mvau.name)
    print("Input shape: " + str(mvau_inst.get_folded_input_shape()))
    print("Output shape: " + str(mvau_inst.get_folded_output_shape()))
```
```bash
#출력
In the original model (pe=simd=1): 
Layer: MVAU_hls_0
Input shape: (1, 600, 1)
Output shape: (1, 64, 1)
Layer: MVAU_hls_1
Input shape: (1, 64, 1)
Output shape: (1, 64, 1)
Layer: MVAU_hls_2
Input shape: (1, 64, 1)
Output shape: (1, 64, 1)
Layer: MVAU_hls_3
Input shape: (1, 64, 1)
Output shape: (1, 1, 1)
```
<br>

```python
# Updated model
list_of_mvaus = model_updated.get_nodes_by_op_type("MVAU_hls")
print("In the original model (pe=simd=1): ")
for mvau in list_of_mvaus:
    mvau_inst = getCustomOp(mvau)
    print("Layer: " + mvau.name)
    print("Input shape: " + str(mvau_inst.get_folded_input_shape()))
    print("Output shape: " + str(mvau_inst.get_folded_output_shape()))
```
```bash
#출력
In the original model (pe=simd=1): 
Layer: MVAU_hls_0
Input shape: (1, 120, 5)
Output shape: (1, 32, 2)
Layer: MVAU_hls_1
Input shape: (1, 64, 1)
Output shape: (1, 64, 1)
Layer: MVAU_hls_2
Input shape: (1, 64, 1)
Output shape: (1, 64, 1)
Layer: MVAU_hls_3
Input shape: (1, 64, 1)
Output shape: (1, 1, 1)
```
<br>

---
### 7.11. Important Note : StreamingDataWidthConverters - 2 
---
폴딩 인자를 변경한 후 MVAU_hls_0의 입력 및 출력 모양이 변경된 것을 볼 수 있습니다.

이러한 변화는 인/아웃 스트림 폭에 직접적인 영향을 미칩니다.

MVAU의 스트림 폭을 계산하는 공식을 자세히 살펴볼 수 있습니다.

```python
showSrc(mvau_inst.get_instream_width)
```
```bash
#출력
    def get_instream_width(self, ind=0):
        i_bits = self.get_input_datatype().bitwidth()
        in_width = i_bits * self.get_nodeattr("SIMD")
        return in_width
```
<br>

```python
showSrc(mvau_inst.get_outstream_width)
```
```bash
#출력
    def get_outstream_width(self, ind=0):
        o_bits = self.get_output_datatype().bitwidth()
        out_width = o_bits * self.get_nodeattr("PE")
        return out_width

```
<br>

입력 스트림 폭은 입력 비트 폭에 SIMD를 곱하여 계산할 수 있으며, 출력 스트림 폭은 출력 비트 폭에 PE를 곱하여 계산할 수 있습니다.

최종 설계를 위해 두 레이어를 서로 연결하려면 한 노드의 입력 스트림 폭이 이전 노드의 출력 스트림 폭과 일치해야 합니다.

그렇지 않은 경우 FINN은 이 불일치를 해결하기 위해 DWC(DataWidthConverter)를 삽입합니다.

---
## 7.12. Important Note : StreamingDataWidthConverters - 3
---
병렬화 파라미터를 업데이트하기 전에 레이어의 입력/출력 스트림 폭을 살펴봅시다.

```python
# Original model
list_of_mvaus = model_orig.get_nodes_by_op_type("MVAU_hls")
print("In the original model (pe=simd=1): ")
for mvau in list_of_mvaus:
    mvau_inst = getCustomOp(mvau)
    print("Layer: " + mvau.name)
    print("Input stream width: " + str(mvau_inst.get_instream_width()))
    print("Output stream width: " + str(mvau_inst.get_outstream_width()))
```
```bash
#출력
In the original model (pe=simd=1): 
Layer: MVAU_hls_0
Input stream width: 1
Output stream width: 2
Layer: MVAU_hls_1
Input stream width: 2
Output stream width: 2
Layer: MVAU_hls_2
Input stream width: 2
Output stream width: 2
Layer: MVAU_hls_3
Input stream width: 2
Output stream width: 1
```
<br>

원본 모델에서 한 레이어의 출력 스트림 폭은 다음 레이어의 입력 스트림 폭과 일치합니다.

따라서 최종 디자인을 생성할 때 DWC가 필요하지 않습니다.

---
### 7.13. Important Note : StreamingDataWidthConverters -4
---

업데이트된 모델의 경우 상황이 다릅니다. 스트림 폭이 어떻게 변경되었는지 살펴보겠습니다.

```python
# Updated model
list_of_mvaus = model_updated.get_nodes_by_op_type("MVAU_hls")
print("In the original model (pe=simd=1): ")
for mvau in list_of_mvaus:
    mvau_inst = getCustomOp(mvau)
    print("Layer: " + mvau.name)
    print("Input stream width: " + str(mvau_inst.get_instream_width()))
    print("Output stream width: " + str(mvau_inst.get_outstream_width()))
```
```bash
#출력
In the original model (pe=simd=1): 
Layer: MVAU_hls_0
Input stream width: 5
Output stream width: 4
Layer: MVAU_hls_1
Input stream width: 2
Output stream width: 2
Layer: MVAU_hls_2
Input stream width: 2
Output stream width: 2
Layer: MVAU_hls_3
Input stream width: 2
Output stream width: 1
```
<br>

보시다시피 MVAU_hls_0의 출력 스트림 폭은 이제 `4`로 변경되었지만 MatrixVectorActivation_1의 입력 스트림 폭은 `2`를 유지했습니다. 

따라서 FINN 컴파일러는 이 노드 사이에 DWC를 삽입할 것이고, 먼저 `InsertDWC` 변환을 호출한 다음 `SpecializeLayers`를 호출하여 결과 DWC를 HLS 또는 RTL 변형으로 변환함으로써 이 동작을 수동으로 호출할 수 있습니다.

```python
from finn.transformation.fpgadataflow.insert_dwc import InsertDWC
from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers

model_updated = model_updated.transform(InsertDWC())
model_updated = model_updated.transform(SpecializeLayers("xc7z020clg400-1"))
model_updated = model_updated.transform(GiveUniqueNodeNames())
```
<br>

```python
model_updated.save("cybsec_DWC.onnx")
showInNetron("cybsec_DWC.onnx")
```
<br>

-오닉스

모델에서 처음 두 레이어 사이에 DWC가 삽입된 것을 확인할 수 있습니다.

DWC는 최종 FINN 설계에서 하드웨어 블록이 되므로 지연 시간과 리소스가 관련되어 있습니다.

---
## 7.13. Important Note : StreamingDataWidthConverters -4
---
리소스 추정치를 마지막으로 살펴보겠습니다.

```python
model_dwc = ModelWrapper("cybsec_DWC.onnx")
res_dict_dwc = model_dwc.analysis(partial(res_estimation, fpgapart="xc7z020clg400-1"))
res_dict_dwc
```
```bash
#출력
{'MVAU_hls_0': {'BRAM_18K': 8,
  'BRAM_efficiency': 0.5208333333333334,
  'LUT': 418,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'StreamingDataWidthConverter_rtl_0': {'BRAM_18K': 0,
  'BRAM_efficiency': 1,
  'LUT': 3,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_1': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.4444444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_2': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.4444444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0},
 'MVAU_hls_3': {'BRAM_18K': 1,
  'BRAM_efficiency': 0.006944444444444444,
  'LUT': 320,
  'URAM': 0,
  'URAM_efficiency': 1,
  'DSP': 0}}
```
<br>

이제 레이어가 하나 더 추가되었으므로 데이터를 조작하여 플롯의 레이어 이름을 줄입니다.

```python
layers = res_dict_dwc.keys()
# replace names of layers with abbreviations
layers = [n.replace("StreamingDataWidthConverter_Batch", "DWC") for n in layers]
```
<br>

```python
# Extracting LUTs from res_dict
LUTs_dwc = [res_dict_dwc[key]["LUT"] for key in res_dict_dwc.keys()]   

#Plotting the bar graph of each network layer with their corresponding LUT resource utilization
fig = plt.figure(figsize = (10, 5))
plt.bar(layers, LUTs_dwc, color ='red', width = 0.3)
plt.xlabel("Network Layers")
plt.ylabel("LUT Utilisation")
plt.title("Estimated LUT values used for each network layer")
plt.show()
```
<br>

-이미지

예제 네트워크의 경우, 그래프에서 볼 수 있듯이 `StreamingDataWidthConverter_Batch` 계층은 많은 수의 LUT 리소스를 소비하지 않습니다. 더 큰 모델이나 삽입된 DWC의 수가 많은 경우에는 상황이 달라질 수 있습니다.\

네트워크의 폴딩 계수를 설정할 때 이 점에 유의하세요.

---